{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf05385",
   "metadata": {},
   "source": [
    "# KNN models - Machine Learning CUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7b8068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab59490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mee_f(Y_true, Y_pred):\n",
    "    \n",
    "    return (1/Y_true.shape[0])*np.sqrt(np.square(Y_true[:,0] - Y_pred[:,0]) + np.square(Y_true[:,1] - Y_pred[:,1])).sum()\n",
    "\n",
    "\n",
    "def neg_mee_f(Y_true, Y_pred):\n",
    "    \n",
    "    return -(1/Y_true.shape[0])*np.sqrt(np.square(Y_true[:,0] - Y_pred[:,0]) + np.square(Y_true[:,1] - Y_pred[:,1])).sum()\n",
    "\n",
    "\n",
    "def selecting_results(df, param_metric_value, param_weights_value):\n",
    "    \"\"\"\n",
    "    This function select, from the gridsearch table, rows related to a specific combination of hyperparameter\n",
    "    leaving free the hyperparameter k (nth-neighbour)\n",
    "     \n",
    "    \"\"\"\n",
    "    \n",
    "    df = df[df[\"param_metric\"] == param_metric_value]\n",
    "    df = df[df[\"param_weights\"] == param_weights_value]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11ca53",
   "metadata": {},
   "source": [
    "# Importing datasets \"ML-CUP22-TR\" and \"ML-CUP22-TS\" (Blind Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03f0637",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pd.read_csv('ML-CUP22-TR.csv', skiprows=7, header=None)\n",
    "tr = tr.drop([0], axis=1).rename(columns={i:i-1 for i in tr.columns})\n",
    "blind_ts = pd.read_csv('ML-CUP22-TS.csv', skiprows=7, header=None)\n",
    "blind_ts = blind_ts.drop([0], axis=1).rename(columns={i:i-1 for i in blind_ts.columns})\n",
    "     \n",
    "X_blind = blind_ts.values\n",
    "X = tr.iloc[:,:9].values\n",
    "Y = tr.iloc[:,9:].values\n",
    "\n",
    "# HOLD-OUT TR_&_TS CUP\n",
    "X_tr, X_tt, Y_tr, Y_tt = train_test_split(\n",
    "    X, Y, test_size=0.3, random_state=0, shuffle=True)\n",
    " \n",
    "y1_tr, y2_tr = Y_tr[:,0], Y_tr[:,1]\n",
    "y1_tt, y2_tt = Y_tt[:,0], Y_tt[:,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d678b3",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "- Data Normalization: ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00e60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization so that for each feature mean = 0 and std = 1 (implemented by StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_tt = scaler.transform(X_tt)\n",
    "blind_ts = scaler.transform(X_blind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a6e312",
   "metadata": {},
   "source": [
    "# KNN model with 2 outputs (Double KNN)\n",
    "\n",
    "- Approach:\n",
    "-1) Initial Hold-out of \"ML-CUP22-TR\" dataset: Design set (X_tr, Y_tr) + Test set (X_tt, Y_tt)  \n",
    "-2) Grid Search through a RepeatedKFold (Repeated: 10 times, #folds: 5) over the Design Set\n",
    "-3) Find the best hyperparameters (basing the decision on the Mean Euclidean Error (MEE))\n",
    "-4) Compute the MEE over the Test set (X_tt, Y_tt) to give an estimation of the future performances of the model found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16481672",
   "metadata": {},
   "source": [
    "## Model Selection \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a63872",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Scorer on which to base the decision of the best model (Negative Mean Euclidean Error scorer)\n",
    "mee_scorer = make_scorer(neg_mee_f, greater_is_better=True)\n",
    "\n",
    "n_neighbors_v = np.arange(1, 51, step = 1)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": n_neighbors_v,\n",
    "    \"weights\": [\"distance\", \"uniform\"],\n",
    "    \"metric\": [\"cityblock\", \"euclidean\", \"cosine\"]\n",
    "}\n",
    "\n",
    "grid_double_knn = GridSearchCV(\n",
    "    KNeighborsRegressor(),\n",
    "    param_grid=param_grid,\n",
    "    scoring = mee_scorer,\n",
    "    cv=RepeatedKFold(n_splits=5, n_repeats=10, random_state=0),\n",
    "    n_jobs=-1,\n",
    "    refit = True,\n",
    "    return_train_score = True\n",
    ")\n",
    "\n",
    "#Â Train a single model which has two outputs (y_pred_1 and y_pred_2)\n",
    "grid_double_knn.fit(X_tr, Y_tr)  \n",
    "\n",
    "\n",
    "cv_results = pd.DataFrame(grid_double_knn.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5041af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the grid search results of doulbe_knn\n",
    "pd.DataFrame(grid_double_knn.cv_results_).to_csv(\"grid_double_knn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24f1208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the first 10 results of the grid search\n",
    "results_sorted = cv_results.sort_values(\"rank_test_score\", axis = 0)\n",
    "results_sorted.iloc[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517ddd6e",
   "metadata": {},
   "source": [
    "### Selecting the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c74c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_table = cv_results[cv_results[\"rank_test_score\"] == 1] #best model (Highest neg_MEE over VL_s)\n",
    "best_model_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d3ff8",
   "metadata": {},
   "source": [
    "### Extracting the hyperparameters of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a9e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = best_model_table[\"param_n_neighbors\"].iloc[0] # #n-neightbours of the best model\n",
    "best_weigths = best_model_table[\"param_weights\"].iloc[0] # \"weights\" attribute of the best model\n",
    "best_metric = best_model_table[\"param_metric\"].iloc[0] # Metric choosen to compute distance for the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc50ec4",
   "metadata": {},
   "source": [
    "### From the results of grid_double_knn select the rows that have the same \"metric\" and \"weights\" hyperparameters as the best one\n",
    "- To do this has been used the function selecting_results (Implemented in the first part of the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aee2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = selecting_results(cv_results, best_metric, best_weigths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc068f34",
   "metadata": {},
   "source": [
    "## Plotting MEE vs n_neighbors (k) for each model of \"models\" table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.array(models[\"param_n_neighbors\"], dtype = int)\n",
    "y_val = np.array(-models[\"mean_test_score\"], dtype = float)\n",
    "std_y_val = np.array(models[\"std_test_score\"], dtype = float)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(x_val, y_val, color = \"r\", linestyle = \"-\", marker = \".\", markersize = 8, linewidth = 1, label = \"Validation MEE\")\n",
    "ax1.fill_between(x_val, y_val-std_y_val, y_val+std_y_val, alpha = 0.4, label = \"$\\pm$ std(Validation MEE)\")\n",
    "ax1.grid()\n",
    "ax1.set_ylabel(\"MEE\")\n",
    "ax1.set_xlabel(\"n_neighbors\")\n",
    "title_str = \"ML CUP - Weights = \" + best_weigths + \", \" + \"metric = \" + best_metric + \", KNN two outputs \"  \n",
    "ax1.set_title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_model_table[\"param_n_neighbors\"].iloc[0])\n",
    "x_best = list(models[\"mean_test_score\"]).index(max(models[\"mean_test_score\"])) +1\n",
    "ax1.axvline(x=x_best, color='g', label = best_k_sting)\n",
    "ax1.legend()\n",
    "plt.savefig(\"MEE_vs_k.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9585c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(models[\"param_n_neighbors\"], models[\"std_test_score\"], marker='.', label = \"Validation error (std value)\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"MEE std.\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "title_str = \"ML CUP - Weights = \" + best_weigths + \", \" + \"metric = \" + best_metric + \", KNN two outputs \"\n",
    "plt.title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_model_table[\"param_n_neighbors\"].iloc[0])\n",
    "x_best = list(models[\"mean_test_score\"]).index(max(models[\"mean_test_score\"])) +1\n",
    "plt.axvline(x=x_best, color='g', label = best_k_sting)\n",
    "plt.legend()\n",
    "plt.savefig(\"MEE_std_vs_k.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925cc5a",
   "metadata": {},
   "source": [
    "## Mean and std MEE computed over TR vs n_neighbors (k) for each model of \"models\" table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad55ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(models[\"param_n_neighbors\"], dtype = int)\n",
    "y_train = np.array(-models[\"mean_train_score\"], dtype = float)\n",
    "std_y_train = np.array(models[\"std_train_score\"], dtype = float)\n",
    "\n",
    "\n",
    "fig, ax2 = plt.subplots()\n",
    "ax2.plot(x_train,y_train, color = \"r\", linestyle = \"-\", marker = \".\", markersize = 8, linewidth = 1, label = \"Training MEE\")\n",
    "ax2.fill_between(x_train, y_train-std_y_train, y_train+std_y_train, alpha = 0.4, label = \"$\\pm$ std(Training MEE)\")\n",
    "ax2.grid()\n",
    "ax2.set_ylabel(\"MEE\")\n",
    "ax2.set_xlabel(\"n_neighbors\")\n",
    "title_str = \"ML CUP - Weights = \" + best_weigths + \", \" + \"metric = \" + best_metric + \", KNN two outputs \"\n",
    "ax2.set_title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_model_table[\"param_n_neighbors\"].iloc[0])\n",
    "x_best = list(models[\"mean_test_score\"]).index(max(models[\"mean_test_score\"])) + 1\n",
    "ax2.axvline(x=x_best, color='g', label = best_k_sting)\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f4a7f",
   "metadata": {},
   "source": [
    "### From the results of grid_double_knn select the rows that have the same \"metric\" hyperparameters as the best one and weights = uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c35458",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_uniform = selecting_results(cv_results, best_metric, \"uniform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b82f3d",
   "metadata": {},
   "source": [
    "## Plotting MEE vs n_neighbors (k) for each model of \"models_uniform\" table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1c6a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.array(models_uniform[\"param_n_neighbors\"], dtype = int)\n",
    "y_val = np.array(-models_uniform[\"mean_test_score\"], dtype = float)\n",
    "std_y_val = np.array(models_uniform[\"std_test_score\"], dtype = float)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(x_val, y_val, color = \"r\", linestyle = \"-\", marker = \".\", markersize = 8, linewidth = 1, label = \"Validation MEE\")\n",
    "ax1.fill_between(x_val, y_val-std_y_val, y_val+std_y_val, alpha = 0.4, label = \"$\\pm$ std(Validation MEE)\")\n",
    "ax1.grid()\n",
    "ax1.set_ylabel(\"MEE\")\n",
    "ax1.set_xlabel(\"n_neighbors\")\n",
    "title_str = \"ML CUP - Weights = Uniform,\" + \"metric = \" + best_metric + \", KNN two outputs \"  \n",
    "ax1.set_title(title_str)\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9bb4a0",
   "metadata": {},
   "source": [
    "## Mean and std MEE computed over TR vs n_neighbors (k) for each model of \"models_uniform\" table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879fcf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(models_uniform[\"param_n_neighbors\"], dtype = int)\n",
    "y_train = np.array(-models_uniform[\"mean_train_score\"], dtype = float)\n",
    "std_y_train = np.array(models_uniform[\"std_train_score\"], dtype = float)\n",
    "\n",
    "\n",
    "fig, ax2 = plt.subplots()\n",
    "ax2.plot(x_train,y_train, color = \"r\", linestyle = \"-\", marker = \".\", markersize = 8, linewidth = 1, label = \"Training MEE\")\n",
    "ax2.fill_between(x_train, y_train-std_y_train, y_train+std_y_train, alpha = 0.4, label = \"$\\pm$ std(Training MEE)\")\n",
    "ax2.grid()\n",
    "ax2.set_ylabel(\"MEE\")\n",
    "ax2.set_xlabel(\"n_neighbors\")\n",
    "title_str = \"ML CUP - Weights = Uniform, \" + \"metric = \" + best_metric + \", KNN two outputs \"\n",
    "ax2.set_title(title_str)\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6837d97",
   "metadata": {},
   "source": [
    "- The grid Search results shows that \"weights\" hyperparameter for the best model is \"Uniform\"\n",
    "- The grid Search results shows that \"metric\" hyperparameter for the best model is \"Euclidean\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83495f1",
   "metadata": {},
   "source": [
    "# Model Assesment - KNN - Double Output (Target 1 and Target 2)\n",
    "\n",
    "- Mean Euclidean Error of the model trained over the desing set (X_tr, Y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5574b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fitted_double_knn = grid_double_knn.best_estimator_\n",
    "\n",
    "mean_train_mee = -best_model_table[\"mean_train_score\"].iloc[0]\n",
    "std_train_mee = best_model_table[\"std_train_score\"].iloc[0]\n",
    "\n",
    "mean_val_mee = -best_model_table[\"mean_test_score\"].iloc[0]\n",
    "std_val_mee = best_model_table[\"std_test_score\"].iloc[0]\n",
    "\n",
    "test_mee = mee_f(Y_tt, final_fitted_double_knn.predict(X_tt))\n",
    "\n",
    "\n",
    "print(f\"Train MEE: {mean_train_mee} +- {std_train_mee} \")\n",
    "print(f\"Validation MEE: {mean_val_mee} +- {std_val_mee} \")\n",
    "print(f\"Test MEE: {test_mee}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d9212",
   "metadata": {},
   "source": [
    "- Final Test MEE, excluding \"weights\" = distance in the grid search, is 1.4627\n",
    "- Final Test MEE, including \"weights\" = distance in the grid search, is 1.44\n",
    "- For this reason has been decided to perform a grid search with also \"Weights\" = distance.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f264b7",
   "metadata": {},
   "source": [
    "##  Predicting Target 1 and Target 2 of blind test using \"final_fitted_double_knn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eed7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_blind_pred = final_fitted_double_knn.predict(blind_ts)\n",
    "\n",
    "# Prediction of target 1 for blind test using the KNN trained with both target 1 and 2 (AKA double KNN)\n",
    "y1_blind_double_knn = Y_blind_pred[:,0] \n",
    "\n",
    "# Prediction of target 1 for blind test using the KNN trained with both target 1 and 2 (AKA double KNN)\n",
    "y2_blind_double_knn = Y_blind_pred[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40afa35d",
   "metadata": {},
   "source": [
    "# KNN model with target 1 as output\n",
    "\n",
    "- Approach:\n",
    "-1) Initial Hold-out of \"ML-CUP22-TR\" dataset: Design set (X_tr, y1_tr) + Test set (X_tt, y1_tt)  \n",
    "-2) Grid Search through a RepeatedKFold (Repeated: 10 times, #folds: 5) over the Design Set\n",
    "-3) Find the best hyperparameters (basing the decision on the Mean Euclidean Error (MEE))\n",
    "-4) Compute the MEE over the Test set (X_tt, y1_tt) to give an estimation of the future performances of the model found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7336369c",
   "metadata": {},
   "source": [
    "## Model Selection - Target 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5efe4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_neighbors_v = np.arange(1, 51, step = 1)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": n_neighbors_v,\n",
    "    \"weights\": [\"distance\", 'uniform'],\n",
    "    \"metric\": [\"cityblock\", \"euclidean\", \"cosine\"]\n",
    "}\n",
    "\n",
    "grid_knn1 = GridSearchCV(\n",
    "    KNeighborsRegressor(),\n",
    "    param_grid=param_grid,\n",
    "    scoring = [\"neg_mean_squared_error\"],\n",
    "    cv=RepeatedKFold(n_splits=5, n_repeats=10, random_state=0),\n",
    "    n_jobs=-1,\n",
    "    refit = \"neg_mean_squared_error\",\n",
    "    return_train_score = True\n",
    ")\n",
    "\n",
    "grid_knn1.fit(X_tr, y1_tr)\n",
    "\n",
    "cv_results_1 = pd.DataFrame(grid_knn1.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1287529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the grid search results of knn1\n",
    "pd.DataFrame(grid_knn1.cv_results_).to_csv(\"grid_knn1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bda858",
   "metadata": {},
   "source": [
    "### Selecting the best model for target 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f9e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best model table \n",
    "best_model1_table = cv_results_1[cv_results_1[\"rank_test_neg_mean_squared_error\"] == 1]\n",
    "best_model1_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8683ef86",
   "metadata": {},
   "source": [
    "### Extracting the hyperparameters of the best model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce263c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "best1_k = best_model1_table[\"param_n_neighbors\"].iloc[0]\n",
    "best1_weigths = best_model1_table[\"param_weights\"].iloc[0]\n",
    "best1_metric = best_model1_table[\"param_metric\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87d4c76",
   "metadata": {},
   "source": [
    "### From the results of \"grid_knn1\" select the rows that have the same \"metric\" and \"weights\" hyperparameters as the best one\n",
    "- To do this has been used the function selecting_results (Implemented in the first part of the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c724d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models1 = selecting_results(cv_results_1, best1_metric, best1_weigths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1fe957",
   "metadata": {},
   "source": [
    "### Plotting MEE vs n_neighbors (k) for each model of \"models1\" table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27222a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.array(models1[\"param_n_neighbors\"], dtype = int)\n",
    "y_val = np.array(-models1[\"mean_test_neg_mean_squared_error\"], dtype = float)\n",
    "std_y_val = np.array(models1[\"std_test_neg_mean_squared_error\"], dtype = float)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(x_val, y_val, color = \"r\", linestyle = \"-\", marker = \".\", markersize = 8, linewidth = 1, label = \"Validation MEE\")\n",
    "ax1.fill_between(x_val, y_val-std_y_val, y_val+std_y_val, alpha = 0.4, label = \"$\\pm$ std(Validation MEE)\")\n",
    "ax1.grid()\n",
    "ax1.set_ylabel(\"MEE\")\n",
    "ax1.set_xlabel(\"n_neighbors\")\n",
    "title_str = \"ML CUP - Weights = \" + best1_weigths + \", \" + \"metric = \" + best1_metric + \", KNN target 1 \"\n",
    "ax1.set_title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_model1_table[\"param_n_neighbors\"].iloc[0]) \n",
    "x_best = list(models1[\"mean_test_neg_mean_squared_error\"]).index(max(models1[\"mean_test_neg_mean_squared_error\"])) +1\n",
    "ax1.axvline(x=x_best, color='g', label = best_k_sting)\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b4998",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(models1[\"param_n_neighbors\"], models1[\"std_test_neg_mean_squared_error\"], marker='.', label = \"Validation std(MEE)\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"MSE std.\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "title_str = \"ML CUP - Weights = \" + best1_weigths + \", \" + \"metric = \" + best1_metric + \", KNN target 1 \"\n",
    "plt.title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_model1_table[\"param_n_neighbors\"].iloc[0])\n",
    "x_best = list(models1[\"mean_test_neg_mean_squared_error\"]).index(max(models1[\"mean_test_neg_mean_squared_error\"]))+1\n",
    "plt.axvline(x=x_best, color='g', label = best_k_sting)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d51fc0",
   "metadata": {},
   "source": [
    "### Mean and std MEE computed over TR vs n_neighbors (k) for each model of \"models1\" table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3245c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(models1[\"param_n_neighbors\"], dtype = int)\n",
    "y_train = np.array(-models1[\"mean_train_neg_mean_squared_error\"], dtype = float)\n",
    "std_y_train = np.array(models1[\"std_train_neg_mean_squared_error\"], dtype = float)\n",
    "\n",
    "\n",
    "fig, ax2 = plt.subplots()\n",
    "ax2.plot(x_train,y_train, color = \"r\", linestyle = \"-\", marker = \".\", markersize = 8, linewidth = 1, label = \"Training MEE\")\n",
    "ax2.fill_between(x_train, y_train-std_y_train, y_train+std_y_train, alpha = 0.4, label = \"$\\pm$ std(Training \\ MEE)\")\n",
    "ax2.grid()\n",
    "ax2.set_ylabel(\"MEE\")\n",
    "ax2.set_xlabel(\"n_neighbors\")\n",
    "title_str = \"ML CUP - Weights = \" + best1_weigths + \", \" + \"metric = \" + best1_metric + \", KNN target 1 \"\n",
    "ax2.set_title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_model1_table[\"param_n_neighbors\"].iloc[0])\n",
    "x_best = list(models1[\"mean_test_neg_mean_squared_error\"]).index(max(models1[\"mean_test_neg_mean_squared_error\"])) +1\n",
    "ax2.axvline(x=x_best, color='g', label = best_k_sting)\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470a8d2e",
   "metadata": {},
   "source": [
    "# Model Assesment - KNN - Output: target 1 \n",
    "\n",
    "- Mean Absolute Error of the model trained over the desing set (X_tr, y1_tr)\n",
    "- Evaluating the MAE over the inner Test Set (X_tt, y1_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e010aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fitted_knn1 = grid_knn1.best_estimator_\n",
    "\n",
    "y1_pred_tr = final_fitted_knn1.predict(X_tr)\n",
    "y1_pred_tt = final_fitted_knn1.predict(X_tt)\n",
    "\n",
    "\n",
    "train_MAE_target1 =  mean_absolute_error(y1_tr, y1_pred_tr)\n",
    "test_MAE_target1 = mean_absolute_error(y1_tt, y1_pred_tt)\n",
    "\n",
    "print(f\"Train MAE target 1: {train_MAE_target1}\")\n",
    "print(f\"Test MAE target 1: {test_MAE_target1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c3f94",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a8e478",
   "metadata": {},
   "source": [
    "# KNN model with target 2 as output\n",
    "\n",
    "- Approach:\n",
    "-1) Initial Hold-out of \"ML-CUP22-TR\" dataset: Design set (X_tr, y2_tr) + Test set (X_tt, y2_tt)  \n",
    "-2) Grid Search through a RepeatedKFold (Repeated: 10 times, #folds: 5) over the Design Set\n",
    "-3) Find the best hyperparameters (basing the decision on the Mean Euclidean Error (MEE))\n",
    "-4) Compute the MEE over the Test set (X_tt, y2_tt) to give an estimation of the future performances of the model found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e32d384",
   "metadata": {},
   "source": [
    "## Model Selection - Target 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9630e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_neighbors_v = np.arange(1, 51, step = 1)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": n_neighbors_v,\n",
    "    \"weights\": [\"distance\", 'uniform'],\n",
    "    \"metric\": [\"cityblock\", \"euclidean\", \"cosine\"]\n",
    "}\n",
    "\n",
    "grid_knn2 = GridSearchCV(\n",
    "    KNeighborsRegressor(),\n",
    "    param_grid=param_grid,\n",
    "    scoring = [\"neg_mean_squared_error\"],\n",
    "    cv=RepeatedKFold(n_splits=5, n_repeats=10, random_state=0),\n",
    "    n_jobs=-1,\n",
    "    refit = \"neg_mean_squared_error\",\n",
    "    return_train_score = True\n",
    ")\n",
    "\n",
    "grid_knn2.fit(X_tr, y2_tr)\n",
    "\n",
    "\n",
    "\n",
    "cv_results_2 = pd.DataFrame(grid_knn2.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35794a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the grid search results of knn2\n",
    "pd.DataFrame(grid_knn2.cv_results_).to_csv(\"grid_knn2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59eea9d",
   "metadata": {},
   "source": [
    "### Selecting the best model for target 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7422ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best model table\n",
    "best_model2_table = cv_results_2[cv_results_2[\"rank_test_neg_mean_squared_error\"] == 1]\n",
    "best_model2_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a7787a",
   "metadata": {},
   "source": [
    "### Extracting the hyperparameters of the best model for target 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff8e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best2_k = best_model2_table[\"param_n_neighbors\"].iloc[0]\n",
    "best2_weigths = best_model2_table[\"param_weights\"].iloc[0]\n",
    "best2_metric = best_model2_table[\"param_metric\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aadd09",
   "metadata": {},
   "source": [
    "### From the results of \"grid_knn2\" select the rows that have the same \"metric\" and \"weights\" hyperparameters as the best one\n",
    "- To do this has been used the function selecting_results (Implemented in the first part of the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a27f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models2 = selecting_results(cv_results_2, best2_metric, best2_weigths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e39e29",
   "metadata": {},
   "source": [
    "### Plotting MEE vs n_neighbors (k) for each model of \"models2\" table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.array(models2[\"param_n_neighbors\"], dtype = int)\n",
    "y_val = np.array(-models2[\"mean_test_neg_mean_squared_error\"], dtype = float)\n",
    "std_y_val = np.array(models2[\"std_test_neg_mean_squared_error\"], dtype = float)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(x_val, y_val, color = \"r\", linestyle = \"-\", marker = \".\", markersize = 8, linewidth = 1, label = \"Validation MEE\")\n",
    "ax1.fill_between(x_val, y_val-std_y_val, y_val+std_y_val, alpha = 0.4, label = \"$\\pm$ std(Validation MEE)\")\n",
    "ax1.grid()\n",
    "ax1.set_ylabel(\"MEE\")\n",
    "ax1.set_xlabel(\"n_neighbors\")\n",
    "title_str = \"ML CUP - Weights = \" + best2_weigths + \", \" + \"metric = \" + best2_metric + \", KNN target 2 \"\n",
    "ax1.set_title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_model2_table[\"param_n_neighbors\"].iloc[0])\n",
    "x_best = list(models2[\"mean_test_neg_mean_squared_error\"]).index(max(models2[\"mean_test_neg_mean_squared_error\"])) +1\n",
    "ax1.axvline(x=x_best, color='g', label = best_k_sting)\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0cf403",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(models2[\"param_n_neighbors\"], models2[\"std_test_neg_mean_squared_error\"], marker='.', label = \"Validation std(MEE)\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"MSE std.\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "title_str = \"ML CUP - Weights = \" + best2_weigths + \", \" + \"metric = \" + best2_metric + \", KNN target 2 \"\n",
    "plt.title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_model2_table[\"param_n_neighbors\"].iloc[0])\n",
    "x_best = list(models2[\"mean_test_neg_mean_squared_error\"]).index(max(models2[\"mean_test_neg_mean_squared_error\"])) + 1\n",
    "plt.axvline(x=x_best, color='g', label = best_k_sting)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7341d6cb",
   "metadata": {},
   "source": [
    "### Mean and std MEE computed over TR vs n_neighbors (k) for each model of \"models2\" table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f8cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(models2[\"param_n_neighbors\"], dtype = int)\n",
    "y_train = np.array(-models2[\"mean_train_neg_mean_squared_error\"], dtype = float)\n",
    "std_y_train = np.array(models2[\"std_train_neg_mean_squared_error\"], dtype = float)\n",
    "\n",
    "\n",
    "fig, ax2 = plt.subplots()\n",
    "ax2.plot(x_train,y_train, color = \"r\", linestyle = \"-\", marker = \".\", markersize = 8, linewidth = 1, label = \"Training MEE\")\n",
    "ax2.fill_between(x_train, y_train-std_y_train, y_train+std_y_train, alpha = 0.4, label = \"$\\pm$ std(Training \\ MEE)\")\n",
    "ax2.grid()\n",
    "ax2.set_ylabel(\"MEE\")\n",
    "ax2.set_xlabel(\"n_neighbors\")\n",
    "title_str = \"ML CUP - Weights = \" + best2_weigths + \", \" + \"metric = \" + best2_metric + \", KNN target 2 \"\n",
    "ax2.set_title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_model2_table[\"param_n_neighbors\"].iloc[0])\n",
    "x_best = list(models2[\"mean_test_neg_mean_squared_error\"]).index(max(models2[\"mean_test_neg_mean_squared_error\"])) +1\n",
    "ax2.axvline(x=x_best, color='g', label = best_k_sting)\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8655d974",
   "metadata": {},
   "source": [
    "# Model Assesment - KNN - Output: target 2 \n",
    "\n",
    "- Mean Absolute Error of the model trained over the desing set (X_tr, y2_tr)\n",
    "- Evaluating the MAE over the inner Test Set (X_tt, y2_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9756d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fitted_knn2 = grid_knn2.best_estimator_\n",
    "\n",
    "y2_pred_tr = final_fitted_knn2.predict(X_tr)\n",
    "y2_pred_tt = final_fitted_knn2.predict(X_tt)\n",
    "\n",
    "\n",
    "train_MAE_target2 =  mean_absolute_error(y2_tr, y2_pred_tr)\n",
    "test_MAE_target2 = mean_absolute_error(y2_tt, y2_pred_tt)\n",
    "\n",
    "\n",
    "print(f\"Train MAE target 2: {train_MAE_target2}\")\n",
    "print(f\"Test MAE target 2: {test_MAE_target2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad88638",
   "metadata": {},
   "source": [
    "## Assessing the goodness of the models (knn_1 and knn2) found by calculating the Mean Euclidean Error (MEE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb9439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_knn_TRAIN_MEE = (1/y1_tr.shape[0])*np.sqrt(np.square(y1_tr - y1_pred_tr) + np.square(y2_tr - y2_pred_tr)).sum()\n",
    "combined_knn_TEST_MEE = (1/y1_tt.shape[0])*np.sqrt(np.square(y1_tt - y1_pred_tt) + np.square(y2_tt - y2_pred_tt)).sum()\n",
    "\n",
    "print(f\"Train MEE (Model 1 and 2 combined): {combined_knn_TRAIN_MEE}\")\n",
    "print(f\"Test MEE (Model 1 and 2 combined): {combined_knn_TEST_MEE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b11e2e4",
   "metadata": {},
   "source": [
    "##  Predicting target 1 and 2 of blind test using respectively \"final_fitted_knn1\" and \"final_fitted_knn2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db7796",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_blind_knn1 = final_fitted_knn1.predict(blind_ts)\n",
    "y2_blind_knn2 = final_fitted_knn2.predict(blind_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2079bb6",
   "metadata": {},
   "source": [
    "## Saving precition over blind test for each model in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629868ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blind_predictions_knn = (pd.DataFrame([y1_blind_double_knn, \n",
    "                                          y2_blind_double_knn,\n",
    "                                          y1_blind_knn1,\n",
    "                                          y2_blind_knn2 ]).T).rename(columns = {  0: \"y1_blind_double_knn\",\n",
    "                                                                                  1: \"y2_blind_double_knn\",\n",
    "                                                                                  2: \"y1_blind_knn1\",\n",
    "                                                                                  3: \"y2_blind_knn2\"\n",
    "                                                                               }\n",
    "                                                                    )\n",
    "df_blind_predictions_knn.to_csv(\"blind_predictions_knn.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
