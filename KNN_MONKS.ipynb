{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4294f322",
   "metadata": {},
   "source": [
    "# MONKS (1,2,3) - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7b8068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9129abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_monks(path):\n",
    "    '''\n",
    "    Function to open monks datasets\n",
    "    Parameters\n",
    "    ---\n",
    "    path : str\n",
    "        It's the path of the file\n",
    "    Returns\n",
    "    ---\n",
    "    monks_df : pandas DataFrame\n",
    "        the df that contains the dataset\n",
    "    \n",
    "    '''    \n",
    "    file = open(path, 'r')\n",
    "    content = file.read().split('\\n') # split to separate different data\n",
    "    monks_df = pd.DataFrame([line.split(' ')[1:] for line in content][:-1]) # creation of the df using separation by ' '\n",
    "    \n",
    "    # The 3 lines below change names to the columns\n",
    "    dict_for_rename = {0:'target', monks_df.shape[1]-1:'id'}\n",
    "    dict_for_rename.update({i:i-1 for i in range(1,monks_df.shape[1]-1)})\n",
    "    monks_df = monks_df.rename(columns=dict_for_rename)\n",
    "    return monks_df\n",
    "\n",
    "\n",
    "def hot_encoding(df):\n",
    "    \n",
    "    \n",
    "    target_column = df.columns[0] # Columns referred to target \n",
    "    y = df[target_column] # selecting target value for each datapoint\n",
    "    y = y.values # from a pd. Dataframe to a np. array\n",
    "    y = np.array(y, dtype=int) # Convert target values from string to int\n",
    "    \n",
    "    \n",
    "    features_columns = df.columns[1:7] # Columns referred to cat. variables\n",
    "    X = df[features_columns] # selecting features columns for each datapoint   \n",
    "    columns = X.columns # Selecting the columns of X. These columns are just the categorical columns of df \n",
    "    X_hot = pd.get_dummies(X, columns=columns) # applying one-hot encoding to X features (from 6 dims to 17 dims)\n",
    "    X_hot = X_hot.values # from a pd. Dataframe to a np. array\n",
    "    \n",
    "    return X_hot, y\n",
    "\n",
    "\n",
    "def not_hot_encoding(df):\n",
    "    \n",
    "    target_column = df.columns[0] # Columns referred to target \n",
    "    y = df[target_column].values #Â selecting target value for each datapoint and switching from a pd. Dataframe to a np. array\n",
    "    y = np.array(y, dtype=int) # Convert target values from string to int\n",
    "    features_columns = df.columns[1:7] # Columns referred to cat. variables\n",
    "    X = df[features_columns].values # selecting features columns for each datapoint  and switching from a pd. Dataframe to a np. array   \n",
    "    X = np.array(X, dtype=int) # # Convert features values from string to int\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "def selecting_results(df, param_metric_value, param_weights_value):\n",
    "    \n",
    "    '''\n",
    "    Function to extrapolate, from the cv_results_ grid, \n",
    "    all the models which have the same best model hyperparameter\n",
    "    \"metric\" and \"weights\"\n",
    "    \n",
    "    Inputs:\n",
    "    df - The cv_results grid converted as a pd. DataFrame\n",
    "    param_metric_value - Metric hyperparameter of the best model\n",
    "    param_weights_value - Weights hyperparameter of the best model\n",
    "    \n",
    "    Outputs:\n",
    "    df - dataframe with the models choosen as explained\n",
    "    \n",
    "    '''\n",
    "    df = df[df[\"param_metric\"] == param_metric_value]\n",
    "    df = df[df[\"param_weights\"] == param_weights_value]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d85127a",
   "metadata": {},
   "source": [
    "### Custom Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6dc392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_nominal(x,y):\n",
    "    return (x!=y).sum()\n",
    "\n",
    "def distance_ordinal(x, y):\n",
    "    return np.sum(np.abs(x-y)/np.array([2, 2, 1, 2, 3, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading Dataset (TR and TS) for each MONK\n",
    "\n",
    "monks1_train = open_monks('monks-1.train')\n",
    "monks1_test = open_monks('monks-1.test')\n",
    "\n",
    "monks2_train = open_monks('monks-2.train')\n",
    "monks2_test = open_monks('monks-2.test')\n",
    "\n",
    "monks3_train = open_monks('monks-3.train')\n",
    "monks3_test = open_monks('monks-3.test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad632d1",
   "metadata": {},
   "source": [
    "# MONK 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8033c4c4",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "- One-hot encoding: ON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = hot_encoding(monks1_train)\n",
    "X_test, y_test = hot_encoding(monks1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897685fa",
   "metadata": {},
   "source": [
    "## Model Selection (Monk 1: one-hot encoding ON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170e75bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors_v = np.arange(1, int(4*X_train.shape[0]/5), step = 1 )\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": n_neighbors_v,\n",
    "    \"weights\": [\"distance\",'uniform'],\n",
    "    \"metric\": [\"cityblock\",\"cosine\"]\n",
    "}\n",
    "\n",
    "\n",
    "grid_1hot = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0),\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    "    return_train_score = True\n",
    ")\n",
    "\n",
    "\n",
    "grid_1hot.fit(X_train, y_train)\n",
    "best_estimator_1hot = grid_1hot.best_estimator_\n",
    "cv_results_1hot = pd.DataFrame(grid_1hot.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best model: It's been choosen the model with the highest mean accuracy value over VL\n",
    "best_model_1hot = cv_results_1hot[cv_results_1hot[\"rank_test_score\"] == 1]\n",
    "best_model_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949dcf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrapolating the hyperparameters of the best model\n",
    "best_n_neighbors_1hot = best_model_1hot[\"param_n_neighbors\"].iloc[0]\n",
    "best_weigths_1hot = best_model_1hot[\"param_weights\"].iloc[0]\n",
    "best_distance_1hot = best_model_1hot[\"param_metric\"].iloc[0]\n",
    "\n",
    "#getting from cv_results_ the mean accuracy value over TR\n",
    "tr_mean_accuracy_1hot = best_model_1hot['mean_train_score'].iloc[0]\n",
    "#getting from cv_results_ the std of accuracy value over TR\n",
    "tr_std_accuracy_1hot = best_model_1hot['std_train_score'].iloc[0]\n",
    "\n",
    "#getting from cv_results_ the mean accuracy value over VL\n",
    "vl_mean_accuracy_1hot = best_model_1hot['mean_test_score'].iloc[0]\n",
    "#getting from cv_results_ the std of accuracy value over VL\n",
    "vl_std_accuracy_1hot = best_model_1hot['std_test_score'].iloc[0]\n",
    "\n",
    "\n",
    "#computing the MSE over TR\n",
    "\n",
    "#computing the MSE over VL\n",
    "\n",
    "\n",
    "print (\"##### BEST MODEL _1hot #####\")\n",
    "print( f\"best n_neighbors: {best_n_neighbors_1hot}\")\n",
    "print(f\"best weigths: {best_weigths_1hot}\")\n",
    "print(f\"best distance: {best_distance_1hot}\")\n",
    "print(f\"Train Accuracy: {tr_mean_accuracy_1hot} +- {tr_std_accuracy_1hot}\")\n",
    "print(f\"Validation Accuracy: {vl_mean_accuracy_1hot} +- {vl_std_accuracy_1hot}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6cc63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting rows which have the hyperparameters metric and weights equals to best ones (referred to the best model).\n",
    "results_1hot = selecting_results(cv_results_1hot, best_distance_1hot, best_weigths_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e20c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results_1hot[\"param_n_neighbors\"], results_1hot[\"mean_test_score\"], marker='.', label = \"Validation Accuracy (mean value)\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"n neighbors\")\n",
    "title_str = \"MONK1, ENC- Weights = \" + best_weigths_1hot + \", \" + \"metric = \" + best_distance_1hot\n",
    "plt.title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_n_neighbors_1hot)\n",
    "plt.axvline(x=best_model_1hot[\"param_n_neighbors\"].iloc[0], color='red', label = best_k_sting)\n",
    "title_str = \"val_acc_vs_k_monk1_hot\" + \".pdf\"\n",
    "plt.legend()\n",
    "plt.savefig(title_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090962a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results_1hot[\"param_n_neighbors\"], results_1hot[\"std_test_score\"], marker='.', label = \"Validation error (std)\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"std Validation Accuracy \")\n",
    "plt.xlabel(\"n neighbors\")\n",
    "title_str = \"MONK1, ENC- Weights = \" + best_weigths_1hot + \", \" + \"metric = \" + best_distance_1hot\n",
    "plt.title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_weigths_1hot)\n",
    "plt.axvline(x=best_model_1hot[\"param_n_neighbors\"].iloc[0], color='red', label = best_k_sting)\n",
    "title_str = \"val_acc_std_vs_k_monk1_hot\" + \".pdf\"\n",
    "plt.legend()\n",
    "plt.savefig(title_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db0bb3c",
   "metadata": {},
   "source": [
    "## Model Assessment (Monk 1: one-hot encoding ON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c673253",
   "metadata": {},
   "source": [
    "### Metrics and Condusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a97387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaulate metrics on the test set\n",
    "y_pred_1hot = best_estimator_1hot.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_1hot))\n",
    "best_estimator_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ebd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = confusion_matrix(y_test, y_pred_1hot)\n",
    "sns.heatmap(cf, annot=True, cmap=\"Greens\")\n",
    "plt.xlabel(\"True label\")\n",
    "plt.ylabel(\"Predicted label\")\n",
    "\n",
    "\n",
    "accuracy_test_1hot = best_estimator_1hot.score(X_test, y_test) \n",
    "print(f\"Test Accuracy_1hot: {accuracy_test_1hot}\")\n",
    "print(f\"Validation Accuracy_1hot: {vl_mean_accuracy_1hot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db0a9d7",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "- One-hot encoding: OFF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f2438",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = not_hot_encoding(monks1_train)\n",
    "X_test, y_test = not_hot_encoding(monks1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488fa41",
   "metadata": {},
   "source": [
    "## Model Selection (Monk 1: one-hot encoding OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00837f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors_v = np.arange(1, int(4*X_train.shape[0]/6), step = 1 )\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": n_neighbors_v,\n",
    "    \"weights\": [\"distance\", 'uniform'],\n",
    "    \"metric\": [distance_nominal, distance_ordinal]\n",
    "}\n",
    "\n",
    "\n",
    "grid_1cold = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0),\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    "    return_train_score = True\n",
    ")\n",
    " \n",
    "\n",
    "grid_1cold.fit(X_train, y_train)\n",
    "best_estimator_1cold = grid_1cold.best_estimator_\n",
    "cv_results_1cold = pd.DataFrame(grid_1cold.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8006db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best model: It's been choosen the model with the highest mean accuracy value over VL\n",
    "best_model_1cold = cv_results_1cold[cv_results_1cold[\"rank_test_score\"] == 1]\n",
    "best_model_1cold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1365c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrapolating the hyperparameters of the best model\n",
    "best_n_neighbors_1cold = best_model_1cold[\"param_n_neighbors\"].iloc[0]\n",
    "best_weigths_1cold = best_model_1cold[\"param_weights\"].iloc[0]\n",
    "best_distance_1cold = best_model_1cold[\"param_metric\"].iloc[0]\n",
    "\n",
    "#getting from cv_results_ the mean accuracy value over TR\n",
    "tr_mean_accuracy_1cold = best_model_1cold['mean_train_score'].iloc[0]\n",
    "#getting from cv_results_ the std of accuracy value over TR\n",
    "tr_std_accuracy_1cold = best_model_1cold['std_train_score'].iloc[0]\n",
    "\n",
    "#getting from cv_results_ the mean accuracy value over VL\n",
    "vl_mean_accuracy_1cold = best_model_1cold['mean_test_score'].iloc[0]\n",
    "#getting from cv_results_ the std of accuracy value over VL\n",
    "vl_std_accuracy_1cold = best_model_1cold['std_test_score'].iloc[0]\n",
    "\n",
    "\n",
    "print (\"##### BEST MODEL _1cold #####\")\n",
    "print( f\"best n_neighbors: {best_n_neighbors_1cold}\")\n",
    "print(f\"best weigths: {best_weigths_1cold}\")\n",
    "print(f\"best distance: {best_distance_1cold}\")\n",
    "print(f\"Train Accuracy: {tr_mean_accuracy_1cold} +- {tr_std_accuracy_1cold}\")\n",
    "print(f\"Validation Accuracy: {vl_mean_accuracy_1cold} +- {vl_std_accuracy_1cold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c77ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting rows which have the hyperparameters metric and weights equals to best ones (referred to the best model).\n",
    "results_1cold = selecting_results(cv_results_1cold, best_distance_1cold, best_weigths_1cold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8be9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results_1cold[\"param_n_neighbors\"], results_1cold[\"mean_test_score\"], marker='.', label = \"Validation Accuracy (mean value)\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"n neighbors\")\n",
    "title_str = \"MONK1, NENC - Weights = \" + best_weigths_1cold + \", \" + \"metric = 'distance_nominal'\" \n",
    "plt.title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_n_neighbors_1cold)\n",
    "plt.axvline(x=best_model_1cold[\"param_n_neighbors\"].iloc[0], color='red', label = best_k_sting)\n",
    "title_str = \"val_acc_vs_k_monk1_cold\" + \".pdf\"\n",
    "plt.legend()\n",
    "plt.savefig(title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47a1050",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results_1cold[\"param_n_neighbors\"], results_1cold[\"std_test_score\"], marker='.', label = \"Validation error (mean value)\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"n neighbors\")\n",
    "title_str = \"MONK1, NENC - Weights = \" + best_weigths_1cold + \", \" + \"metric = 'distance_nominal'\" \n",
    "plt.title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_n_neighbors_1cold)\n",
    "plt.axvline(x=best_model_1cold[\"param_n_neighbors\"].iloc[0], color='red', label = best_k_sting)\n",
    "title_str = \"val_acc_std_vs_k_monk1_cold\" + \".pdf\"\n",
    "plt.legend()\n",
    "plt.savefig(title_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bd14ff",
   "metadata": {},
   "source": [
    "## Model Assessment (Monk 1: one-hot encoding OFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6ce551",
   "metadata": {},
   "source": [
    "### Metrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36fe93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaulate metrics on the test set\n",
    "y_pred_1cold = best_estimator_1cold.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_1cold))\n",
    "best_estimator_1cold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a960f517",
   "metadata": {},
   "source": [
    "### Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc70992",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = confusion_matrix(y_test, y_pred_1cold)\n",
    "sns.heatmap(cf, annot=True, cmap=\"Greens\")\n",
    "plt.xlabel(\"True label\")\n",
    "plt.ylabel(\"Predicted label\")\n",
    "\n",
    "accuracy_test_1cold = best_estimator_1cold.score(X_test, y_test) \n",
    "print(f\"Test Accuracy_1cold: {accuracy_test_1cold}\")\n",
    "print(f\"Validation Accuracy_1cold: {vl_mean_accuracy_1cold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1640e588",
   "metadata": {},
   "source": [
    "# MONK 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ff910",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "- One-hot encoding: ON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f105a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = hot_encoding(monks2_train)\n",
    "X_test, y_test = hot_encoding(monks2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f1ac1",
   "metadata": {},
   "source": [
    "# Model Selection (Monk 2: one-hot encoding ON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d3a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors_v = np.arange(1, int(4*X_train.shape[0]/6), step = 1 )\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": n_neighbors_v,\n",
    "    \"weights\": [\"distance\", 'uniform'],\n",
    "    \"metric\": [\"cityblock\",\"cosine\"]\n",
    "}\n",
    "\n",
    "\n",
    "grid_2hot = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0),\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    "    return_train_score = True\n",
    ")\n",
    " \n",
    "\n",
    "grid_2hot.fit(X_train, y_train)\n",
    "best_estimator_2hot = grid_2hot.best_estimator_\n",
    "cv_results_2hot = pd.DataFrame(grid_2hot.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee9428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best model: It's been choosen the model with the highest mean accuracy value over VL\n",
    "best_model_2hot = cv_results_2hot[cv_results_2hot[\"rank_test_score\"] == 1]\n",
    "best_model_2hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e238861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrapolating the hyperparameters of the best model\n",
    "best_n_neighbors_2hot = best_model_2hot[\"param_n_neighbors\"].iloc[0]\n",
    "best_weigths_2hot = best_model_2hot[\"param_weights\"].iloc[0]\n",
    "best_distance_2hot = best_model_2hot[\"param_metric\"].iloc[0]\n",
    "\n",
    "#getting from cv_results_ the mean accuracy value over TR\n",
    "tr_mean_accuracy_2hot = best_model_2hot['mean_train_score'].iloc[0]\n",
    "#getting from cv_results_ the std of accuracy value over TR\n",
    "tr_std_accuracy_2hot = best_model_2hot['std_train_score'].iloc[0]\n",
    "\n",
    "#getting from cv_results_ the mean accuracy value over VL\n",
    "vl_mean_accuracy_2hot = best_model_2hot['mean_test_score'].iloc[0]\n",
    "#getting from cv_results_ the std of accuracy value over VL\n",
    "vl_std_accuracy_2hot = best_model_2hot['std_test_score'].iloc[0]\n",
    "\n",
    "\n",
    "print (\"##### BEST MODEL _2hot #####\")\n",
    "print( f\"best n_neighbors: {best_n_neighbors_2hot}\")\n",
    "print(f\"best weigths: {best_weigths_2hot}\")\n",
    "print(f\"best distance: {best_distance_2hot}\")\n",
    "print(f\"Train Accuracy: {tr_mean_accuracy_2hot} +- {tr_std_accuracy_2hot}\")\n",
    "print(f\"Validation Accuracy: {vl_mean_accuracy_2hot} +- {vl_std_accuracy_2hot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdd7c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting rows which have the hyperparameters metric and weights equals to best ones (referred to the best model).\n",
    "results_2hot = selecting_results(cv_results_2hot, best_distance_2hot, best_weigths_2hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dda150",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results_2hot[\"param_n_neighbors\"], results_2hot[\"mean_test_score\"], marker='.', label = \"Validation Accuracy (mean value)\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"n neighbors\")\n",
    "title_str = \"MONK2, ENC - Weights = \" + best_weigths_2hot+ \", \" + \"metric = \" + best_distance_2hot\n",
    "plt.title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_n_neighbors_2hot)\n",
    "plt.axvline(x=best_model_2hot[\"param_n_neighbors\"].iloc[0], color='red', label = best_k_sting)\n",
    "title_str = \"val_acc_vs_k_monk2_hot\" + \".pdf\"\n",
    "plt.legend()\n",
    "plt.savefig(title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3326811",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results_2hot[\"param_n_neighbors\"], results_2hot[\"std_test_score\"], marker='.', label = \"Validation error (mean value)\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"n neighbors\")\n",
    "title_str = \"MONK2, ENC - Weights = \" + best_weigths_2hot+ \", \" + \"metric = \" + best_distance_2hot\n",
    "plt.title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_n_neighbors_2hot)\n",
    "plt.axvline(x=best_model_2hot[\"param_n_neighbors\"].iloc[0], color='red', label = best_k_sting)\n",
    "title_str = \"val_acc_std_vs_k_monk2_hot\" + \".pdf\"\n",
    "plt.legend()\n",
    "plt.savefig(title_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d441bef",
   "metadata": {},
   "source": [
    "# Model Assessment (Monk 2: one-hot encoding ON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8affb0be",
   "metadata": {},
   "source": [
    "## Metrics and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7236facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaulate metrics on the test set\n",
    "y_pred_2hot = best_estimator_2hot.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_2hot))\n",
    "best_estimator_2hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acaeb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = confusion_matrix(y_test, y_pred_2hot)\n",
    "sns.heatmap(cf, annot=True, cmap=\"Greens\")\n",
    "plt.xlabel(\"True label\")\n",
    "plt.ylabel(\"Predicted label\")\n",
    "\n",
    "accuracy_test_2hot = best_estimator_2hot.score(X_test, y_test) \n",
    "print(f\"Test Accuracy_2hot: {accuracy_test_2hot}\")\n",
    "print(f\"Validation Accuracy_2hot: {vl_mean_accuracy_2hot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b66302",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "- One-hot encoding: OFF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9b4a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = not_hot_encoding(monks2_train)\n",
    "X_test, y_test = not_hot_encoding(monks2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5d4044",
   "metadata": {},
   "source": [
    "# Model Selection (Monk 2: one-hot encoding OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3451c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors_v = np.arange(1, int(4*X_train.shape[0]/6), step = 1 )\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": n_neighbors_v,\n",
    "    \"weights\": [\"distance\", 'uniform'],\n",
    "    \"metric\": [distance_nominal, distance_ordinal]\n",
    "}\n",
    "\n",
    "\n",
    "grid_2cold = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0),\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    "    return_train_score = True\n",
    ")\n",
    " \n",
    "\n",
    "grid_2cold.fit(X_train, y_train)\n",
    "best_estimator_2cold = grid_2cold.best_estimator_\n",
    "cv_results_2cold = pd.DataFrame(grid_2cold.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b3f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best model: It's been choosen the model with the highest mean accuracy value over VL\n",
    "best_model_2cold = cv_results_2cold[cv_results_2cold[\"rank_test_score\"] == 1]\n",
    "best_model_2cold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7516154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrapolating the hyperparameters of the best model\n",
    "best_n_neighbors_2cold = best_model_2cold[\"param_n_neighbors\"].iloc[0]\n",
    "best_weigths_2cold = best_model_2cold[\"param_weights\"].iloc[0]\n",
    "best_distance_2cold = best_model_2cold[\"param_metric\"].iloc[0]\n",
    "\n",
    "#getting from cv_results_ the mean accuracy value over TR\n",
    "tr_mean_accuracy_2cold = best_model_2cold['mean_train_score'].iloc[0]\n",
    "#getting from cv_results_ the std of accuracy value over TR\n",
    "tr_std_accuracy_2cold = best_model_2cold['std_train_score'].iloc[0]\n",
    "\n",
    "#getting from cv_results_ the mean accuracy value over VL\n",
    "vl_mean_accuracy_2cold = best_model_2cold['mean_test_score'].iloc[0]\n",
    "#getting from cv_results_ the std of accuracy value over VL\n",
    "vl_std_accuracy_2cold = best_model_2cold['std_test_score'].iloc[0]\n",
    "\n",
    "\n",
    "print (\"##### BEST MODEL _2cold #####\")\n",
    "print( f\"best n_neighbors: {best_n_neighbors_2cold}\")\n",
    "print(f\"best weigths: {best_weigths_2cold}\")\n",
    "print(f\"best distance: {best_distance_2cold}\")\n",
    "print(f\"Train Accuracy: {tr_mean_accuracy_2cold} +- {tr_std_accuracy_2cold}\")\n",
    "print(f\"Validation Accuracy: {vl_mean_accuracy_2cold} +- {vl_std_accuracy_2cold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dad8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting rows which have the hyperparameters metric and weights equals to best ones (referred to the best model).\n",
    "results_2cold = selecting_results(cv_results_2cold, best_distance_2cold, best_weigths_2cold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad02cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results_2cold[\"param_n_neighbors\"], results_2cold[\"mean_test_score\"], marker='.', label = \"Validation Accuracy (mean value)\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"n neighbors\")\n",
    "title_str = \"MONK2, NENC - Weights = \" + best_weigths_2cold + \", \" + \"metric = 'distance_ordinal'\" \n",
    "plt.title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_n_neighbors_2cold)\n",
    "plt.axvline(x=best_model_2cold[\"param_n_neighbors\"].iloc[0], color='red', label = best_k_sting)\n",
    "title_str = \"val_acc_vs_k_monk2_cold\" + \".pdf\"\n",
    "plt.legend()\n",
    "plt.savefig(title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42dd7bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(results_2cold[\"param_n_neighbors\"], results_2cold[\"std_test_score\"], marker='.', label = \"Validation error (mean value)\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"n neighbors\")\n",
    "title_str = \"MONK2, NENC - Weights = \" + best_weigths_2cold + \", \" + \"metric = 'distance_ordinal'\" \n",
    "plt.title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_n_neighbors_2cold)\n",
    "plt.axvline(x=best_model_2cold[\"param_n_neighbors\"].iloc[0], color='red', label = best_k_sting)\n",
    "title_str = \"val_acc_std_vs_k_monk2_cold\" + \".pdf\"\n",
    "plt.legend()\n",
    "plt.savefig(title_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738d5440",
   "metadata": {},
   "source": [
    "# Model Assessment (Monk 2: one-hot encoding OFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a10ed33",
   "metadata": {},
   "source": [
    "## Metrics and Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5a5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaulate metrics on the test set\n",
    "y_pred_2cold = best_estimator_2cold.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_2cold))\n",
    "best_estimator_2cold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cc58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = confusion_matrix(y_test, y_pred_2cold)\n",
    "sns.heatmap(cf, annot=True, cmap=\"Greens\")\n",
    "plt.xlabel(\"True label\")\n",
    "plt.ylabel(\"Predicted label\")\n",
    "\n",
    "accuracy_test_2cold = best_estimator_2cold.score(X_test, y_test) \n",
    "print(f\"Test Accuracy_2cold: {accuracy_test_2cold}\")\n",
    "print(f\"Validation Accuracy_2cold: {vl_mean_accuracy_2cold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d5bb87",
   "metadata": {},
   "source": [
    "# MONK 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd34f7",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "- One-hot encoding: ON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef86eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = hot_encoding(monks3_train)\n",
    "X_test, y_test = hot_encoding(monks3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a080bd",
   "metadata": {},
   "source": [
    "# Model Selection (Monk 3: one-hot encoding ON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be9ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors_v = np.arange(1, int(4*X_train.shape[0]/6), step = 1 )\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": n_neighbors_v,\n",
    "    \"weights\": [\"distance\", 'uniform'],\n",
    "    \"metric\": [\"cityblock\",\"cosine\"]\n",
    "}\n",
    "\n",
    "\n",
    "grid_3hot = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0),\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    "    return_train_score = True\n",
    ")\n",
    " \n",
    "\n",
    "grid_3hot.fit(X_train, y_train)\n",
    "best_estimator_3hot = grid_3hot.best_estimator_\n",
    "cv_results_3hot = pd.DataFrame(grid_3hot.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81579485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best model: It's been choosen the model with the highest mean accuracy value over VL\n",
    "best_model_3hot = cv_results_3hot[cv_results_3hot[\"rank_test_score\"] == 1]\n",
    "best_model_3hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf0693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrapolating the hyperparameters of the best model\n",
    "best_n_neighbors_3hot = best_model_3hot[\"param_n_neighbors\"].iloc[0]\n",
    "best_weigths_3hot = best_model_3hot[\"param_weights\"].iloc[0]\n",
    "best_distance_3hot = best_model_3hot[\"param_metric\"].iloc[0]\n",
    "\n",
    "#getting from cv_results_ the mean accuracy value over TR\n",
    "tr_mean_accuracy_3hot = best_model_3hot['mean_train_score'].iloc[0]\n",
    "#getting from cv_results_ the std of accuracy value over TR\n",
    "tr_std_accuracy_3hot = best_model_3hot['std_train_score'].iloc[0]\n",
    "\n",
    "#getting from cv_results_ the mean accuracy value over VL\n",
    "vl_mean_accuracy_3hot = best_model_3hot['mean_test_score'].iloc[0]\n",
    "#getting from cv_results_ the std of accuracy value over VL\n",
    "vl_std_accuracy_3hot = best_model_3hot['std_test_score'].iloc[0]\n",
    "\n",
    "\n",
    "print (\"##### BEST MODEL _3hot #####\")\n",
    "print( f\"best n_neighbors: {best_n_neighbors_3hot}\")\n",
    "print(f\"best weigths: {best_weigths_3hot}\")\n",
    "print(f\"best distance: {best_distance_3hot}\")\n",
    "print(f\"Train Accuracy: {tr_mean_accuracy_3hot} +- {tr_std_accuracy_3hot}\")\n",
    "print(f\"Validation Accuracy: {vl_mean_accuracy_3hot} +- {vl_std_accuracy_3hot}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0654d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting rows which have the hyperparameters metric and weights equals to best ones (referred to the best model).\n",
    "results_3hot = selecting_results(cv_results_3hot, best_distance_3hot, best_weigths_3hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c57bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results_3hot[\"param_n_neighbors\"], results_3hot[\"mean_test_score\"], marker='.', label = \"Validation Accuracy (mean value)\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"n neighbors\")\n",
    "title_str = \"MONK3, ENC - Weights = \" + best_weigths_3hot + \", \" + \"metric = \" + best_distance_3hot\n",
    "plt.title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_n_neighbors_3hot)\n",
    "plt.axvline(x=best_model_3hot[\"param_n_neighbors\"].iloc[0], color='red', label = best_k_sting)\n",
    "title_str = \"val_acc_vs_k_monk3_hot\" + \".pdf\"\n",
    "plt.legend()\n",
    "plt.savefig(title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b41f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results_3hot[\"param_n_neighbors\"], results_3hot[\"std_test_score\"], marker='.', label = \"Validation error (mean value)\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"n neighbors\")\n",
    "title_str = \"MONK3, ENC - Weights = \" + best_weigths_3hot + \", \" + \"metric = \" + best_distance_3hot\n",
    "plt.title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_n_neighbors_3hot)\n",
    "plt.axvline(x=best_model_3hot[\"param_n_neighbors\"].iloc[0], color='red', label = best_k_sting)\n",
    "title_str = \"val_acc_std_vs_k_monk3_hot\" + \".pdf\"\n",
    "plt.legend()\n",
    "plt.savefig(title_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c408bb57",
   "metadata": {},
   "source": [
    "# Model Assessment (Monk 3: one-hot encoding ON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29735dc",
   "metadata": {},
   "source": [
    "## Metrics and Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f18ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaulate metrics on the test set\n",
    "y_pred_3hot = best_estimator_3hot.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_3hot))\n",
    "best_estimator_3hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbab007",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = confusion_matrix(y_test, y_pred_3hot)\n",
    "sns.heatmap(cf, annot=True, cmap=\"Greens\")\n",
    "plt.xlabel(\"True label\")\n",
    "plt.ylabel(\"Predicted label\")\n",
    "\n",
    "accuracy_test_3hot = best_estimator_3hot.score(X_test, y_test) \n",
    "print(f\"Test Accuracy_3hot: {accuracy_test_3hot}\")\n",
    "print(f\"Validation Accuracy_3hot: {vl_mean_accuracy_3hot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fa3e51",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "- One-hot encoding: OFF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f9be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = not_hot_encoding(monks3_train)\n",
    "X_test, y_test = not_hot_encoding(monks3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e20a581",
   "metadata": {},
   "source": [
    "# Model Selection (Monk 3: one-hot encoding OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3207a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors_v = np.arange(1, int(4*X_train.shape[0]/6), step = 1 )\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": n_neighbors_v,\n",
    "    \"weights\": [\"distance\", 'uniform'],\n",
    "    \"metric\": [distance_nominal, distance_ordinal]\n",
    "}\n",
    "\n",
    "\n",
    "grid_3cold = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0),\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    "    return_train_score = True\n",
    ")\n",
    " \n",
    "\n",
    "grid_3cold.fit(X_train, y_train)\n",
    "best_estimator_3cold = grid_3cold.best_estimator_\n",
    "cv_results_3cold= pd.DataFrame(grid_3cold.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1510ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best model: It's been choosen the model with the highest mean accuracy value over VL\n",
    "best_model_3cold = cv_results_3cold[cv_results_3cold[\"rank_test_score\"] == 1]\n",
    "best_model_3cold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52dd4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrapolating the hyperparameters of the best model\n",
    "best_n_neighbors_3cold = best_model_3cold[\"param_n_neighbors\"].iloc[0]\n",
    "best_weigths_3cold = best_model_3cold[\"param_weights\"].iloc[0]\n",
    "best_distance_3cold = best_model_3cold[\"param_metric\"].iloc[0]\n",
    "\n",
    "#getting from cv_results_ the mean accuracy value over TR\n",
    "tr_mean_accuracy_3cold = best_model_3cold['mean_train_score'].iloc[0]\n",
    "#getting from cv_results_ the std of accuracy value over TR\n",
    "tr_std_accuracy_3cold = best_model_3cold['std_train_score'].iloc[0]\n",
    "\n",
    "#getting from cv_results_ the mean accuracy value over VL\n",
    "vl_mean_accuracy_3cold = best_model_3cold['mean_test_score'].iloc[0]\n",
    "#getting from cv_results_ the std of accuracy value over VL\n",
    "vl_std_accuracy_3cold = best_model_3cold['std_test_score'].iloc[0]\n",
    "\n",
    "\n",
    "print (\"##### BEST MODEL _3cold #####\")\n",
    "print( f\"best n_neighbors: {best_n_neighbors_3cold}\")\n",
    "print(f\"best weigths: {best_weigths_3cold}\")\n",
    "print(f\"best distance: {best_distance_3cold}\")\n",
    "print(f\"Train Accuracy: {tr_mean_accuracy_3cold} +- {tr_std_accuracy_3cold}\")\n",
    "print(f\"Validation Accuracy: {vl_mean_accuracy_3cold} +- {vl_std_accuracy_3cold}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0787fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting rows which have the hyperparameters metric and weights equals to best ones (referred to the best model).\n",
    "results_3cold = selecting_results(cv_results_3cold, best_distance_3cold, best_weigths_3cold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bdd8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results_3cold[\"param_n_neighbors\"], results_3cold[\"mean_test_score\"], marker='.', label = \"Validation Accuracy (mean value)\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"n neighbors\")\n",
    "title_str = \"MONK3, NENC - Weights = \" + best_weigths_3cold + \", \" + \"metric = 'distance_ordinal'\" \n",
    "plt.title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_n_neighbors_3cold)\n",
    "plt.axvline(x=best_model_3cold[\"param_n_neighbors\"].iloc[0], color='red', label = best_k_sting)\n",
    "title_str = \"val_acc_vs_k_monk3_cold\" + \".pdf\"\n",
    "plt.legend()\n",
    "plt.savefig(title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4a055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results_3cold[\"param_n_neighbors\"], results_3cold[\"std_test_score\"], marker='.', label = \"Validation error (mean value)\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.xlabel(\"n neighbors\")\n",
    "title_str = \"MONK3, NENC - Weights = \" + best_weigths_3cold + \", \" + \"metric = 'distance_ordinal'\" \n",
    "plt.title(title_str)\n",
    "best_k_sting = \"best n_neighbors = \" + str(best_n_neighbors_3cold)\n",
    "plt.axvline(x=best_model_3cold[\"param_n_neighbors\"].iloc[0], color='red', label = best_k_sting)\n",
    "title_str = \"val_acc_std_vs_k_monk3_cold\" + \".pdf\"\n",
    "plt.legend()\n",
    "plt.savefig(title_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e09092",
   "metadata": {},
   "source": [
    "# Model Assessment (Monk 3: one-hot encoding OFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab006e96",
   "metadata": {},
   "source": [
    "## Metrics and Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaulate metrics on the test set\n",
    "y_pred_3cold = best_estimator_3cold.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_3cold))\n",
    "best_estimator_3cold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a54e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = confusion_matrix(y_test, y_pred_3cold)\n",
    "sns.heatmap(cf, annot=True, cmap=\"Greens\")\n",
    "plt.xlabel(\"True label\")\n",
    "plt.ylabel(\"Predicted label\")\n",
    "\n",
    "\n",
    "accuracy_test_3cold = best_estimator_3cold.score(X_test, y_test) \n",
    "print(f\"Test Accuracy: {accuracy_test_3cold}\")\n",
    "print(f\"Validation Accuracy: {vl_mean_accuracy_3cold}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
