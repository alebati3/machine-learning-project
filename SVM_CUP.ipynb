{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to return a number with fixed numebr of significant digits\n",
    "\n",
    "from math import log10 , floor\n",
    "\n",
    "def round_it(x, sig):\n",
    "    return round(x, sig-int(floor(log10(abs(x))))-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_train_cup(path):\n",
    "    \n",
    "    df = pd.read_csv(path, skiprows=7, header = None)                       \n",
    "    df = df.drop([0], axis = 1)\n",
    "    df = df.rename(columns={\n",
    "        1: 'var_1',\n",
    "        2: 'var_2',\n",
    "        3: 'var_3',\n",
    "        4: 'var_4',\n",
    "        5: 'var_5',\n",
    "        6: 'var_6',\n",
    "        7: 'var_7',\n",
    "        8: 'var_8',\n",
    "        9: 'var_9',\n",
    "        10: 'target_1',\n",
    "        11: 'target_2' \n",
    "    })\n",
    "\n",
    "    X = df.iloc[:, :9].values\n",
    "    \n",
    "    Y = df.iloc[:, 9:11].values\n",
    "    \n",
    "#     y_1 = df.iloc[:, 9:10].values.flatten()\n",
    "    \n",
    "#     y_2 = df.iloc[:, 10:11].values.flatten()\n",
    "    \n",
    "    return df, X, Y \n",
    "\n",
    "\n",
    "def open_blind_test_cup(path):\n",
    "    \n",
    "    df = pd.read_csv(path, skiprows=7, header = None) \n",
    "                     \n",
    "    df = df.drop([0], axis = 1)\n",
    "    X = df.iloc[:, :9].values\n",
    "    \n",
    "    \n",
    "    return df, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening ML-CUP22-TR and ML-CUP22-TR dataset as useful structures\n",
    "\n",
    "df, X, Y = open_train_cup(\"ML-CUP22-TR.csv\")\n",
    "df_blind_test, X_blind_test = open_blind_test_cup(\"ML-CUP22-TS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad463899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0aeab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_design, X_test, Y_design, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.3, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d31032",
   "metadata": {},
   "source": [
    "SVM for regression works well with normalized/standardize dataset, so we decide to use StandardScaler that standardize each attribute on X_design to have mean 0 and variance 1. The same scaling must be applied to X_test and X_blind_test to obtain meaningful results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b51b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8960722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X_design)  \n",
    "X_design = scaler.transform(X_design)  \n",
    "# apply same transformation to test datasets\n",
    "X_test = scaler.transform(X_test) \n",
    "X_blind_test = scaler.transform(X_blind_test)  \n",
    "\n",
    "N_design=X_design.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b37535",
   "metadata": {},
   "source": [
    "now we want to work separately with the 2 target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacfb8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting of targets\n",
    "\n",
    "y_1_design = Y_design[:, 0]\n",
    "y_2_design = Y_design[:, 1]\n",
    "\n",
    "y_1_test = Y_test[:, 0]\n",
    "y_2_test = Y_test[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28e552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b7b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2725afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_grid_search(param_grid, y_design, n):\n",
    "    grid = GridSearchCV(\n",
    "        \n",
    "        SVR(),  # regressor SVM\n",
    "        param_grid = param_grid, # it changes for each kernel\n",
    "        cv = RepeatedKFold(n_splits=5, n_repeats=n, random_state=0),\n",
    "        n_jobs = -1,\n",
    "        scoring = 'neg_mean_absolute_error',\n",
    "        refit=True,\n",
    "        return_train_score=True\n",
    "        \n",
    "    )\n",
    "\n",
    "    return grid.fit(X_design, y_design) # y_design = y_1_design, y_2_design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98f4197",
   "metadata": {},
   "source": [
    "## Target 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1c1ca8",
   "metadata": {},
   "source": [
    "#### RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90106aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) choice of hyperpar.'s ranges to explore\n",
    "\n",
    "C_interval_rbf = np.logspace(-2, 4, 7)\n",
    "gamma_interval_rbf = np.logspace(-4, 2, 7) \n",
    "eps_interval = np.logspace(-2, 0, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76234ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 2) grid search in practice: FIRST RUN THE PREVIOUS CODE!\n",
    "\n",
    "param_grid_rbf_1= {\n",
    "    \n",
    "    'C': C_interval_rbf, \n",
    "    'epsilon': eps_interval,\n",
    "    \n",
    "    'kernel': ['rbf'],\n",
    "    \n",
    "    'gamma': gamma_interval_rbf   \n",
    "    \n",
    "}\n",
    "\n",
    "grid_rbf_1 = my_grid_search(param_grid_rbf_1, y_1_design, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5561ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of useful dataframe\n",
    "\n",
    "a_rbf_1 = pd.read_csv('cup/a_rbf_1_first.csv')\n",
    "\n",
    "b_rbf_1 = a_rbf_1[a_rbf_1['rank_test_score'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f15938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful code for model with 3 hyp. for implementing a heatmap\n",
    "\n",
    "def heatmap_3(a, b, fix_1, var_1, var_2, score_var):\n",
    "    \n",
    "    X = np.unique(b[fix_1].values)  #values for fixed attribute\n",
    "\n",
    "    for j in range(len(X)):\n",
    "\n",
    "        plt.figure(j)\n",
    "        \n",
    "        matrix = a[(a[fix_1] == X[j])]\n",
    "        matrix = matrix[[var_1, var_2, score_var]]\n",
    "\n",
    "        #heatmap in practice\n",
    "        #glue = matrix.pivot(var_1, var_2, score_var)\n",
    "        glue = matrix.pivot(var_1, var_2, score_var)\n",
    "        sns.heatmap(glue, linewidth=.5) # annot=True for values inside the cells\n",
    "        plt.title('$\\epsilon$={}'.format(X[j]))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('{}.pdf'.format(j))\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee832fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# heatmap to visualize graphically the grid search fixing a hyp.(in this case epsilon-> usuful to show its influence on the fsv)\n",
    "\n",
    "heatmap_3(a_rbf_1, a_rbf_1, 'param_epsilon', 'param_C', 'param_gamma', 'mean_test_score')   #or b_rbf_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b28f4c",
   "metadata": {},
   "source": [
    "we want to show the expected relationship between C and gamma at given eps (we don't lose generality due to low influence of our values of eps in terms of validation score). For this reason we plot C vs validation score for eps,gamma that provide the best validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like gamma and C have a relationship for the highest validation score..let's look at spearman correlation coeff.(r)\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "print('r = {}'.format(spearmanr(a_rbf_1[a_rbf_1['mean_test_score'] >= -0.9][['param_C', 'param_gamma']].values)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful code for further purposes \n",
    "\n",
    "def plot_3(a, fix_1, fix_2, var_1, score_var, scale):\n",
    "\n",
    "    X = np.unique(a[[fix_1 , fix_2]].values.astype(None), axis=0) # it avoids to repeat the same rows\n",
    "\n",
    "    for j in range(len(X)): \n",
    "        b=a[(a[fix_1] == X[j][0]) & (a[fix_2] == X[j][1])]\n",
    "        c_best= b[b[score_var] == b[score_var].max()][var_1]\n",
    "        p_ = (X[j][1]) * c_best\n",
    "        plt.figure(j)\n",
    "        plt.plot(\n",
    "            b[var_1],\n",
    "            b[score_var], \n",
    "        )\n",
    "        \n",
    "        plt.scatter( \n",
    "            b[var_1],\n",
    "            b[score_var],\n",
    "            color='b'\n",
    "        )\n",
    "        \n",
    "        plt.scatter( \n",
    "            c_best,\n",
    "            np.ones(len(c_best))*b[score_var].max(),\n",
    "            label='best models',\n",
    "            color='r'\n",
    "       )\n",
    "        p_ = (X[j][1]) * c_best\n",
    "        plt.title('{}={}, {}={}, gamma C={}'.format(fix_1, X[j][0], fix_2, X[j][1], p_))\n",
    "        plt.xlabel(var_1)\n",
    "        plt.ylabel(score_var)\n",
    "        plt.xscale(scale)  #pay attention when you set d\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b38aafa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5) (plot) one hyp. vs validatio_accuracy fixing the others hyp. (at values that maximize the validation_accuracy)\n",
    "\n",
    "score_var='mean_test_score'\n",
    "\n",
    "fix_1= 'param_epsilon'\n",
    "fix_2= 'param_gamma'\n",
    "\n",
    "var_1= 'param_C'\n",
    "\n",
    "plot_3(a_rbf_1[a_rbf_1['param_epsilon'] == 1.0], fix_1, fix_2, var_1, score_var, 'log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f98710",
   "metadata": {},
   "source": [
    "As the theory suggests lower (than 1) values for gamma require higher values of C to obtain a good trade-off for model flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for support vectors analysis\n",
    "# using b_rbf_1, choice of the model with lowest number of support vector\n",
    "# using a_rb, number of support vector for each model included in the grid search\n",
    "\n",
    "def sv_analysis_rbf(df, y_design):\n",
    "    \n",
    "    hyper_pars = df[['param_C', 'param_epsilon', 'param_gamma']].values\n",
    "    n_support = []\n",
    "    model_list = []\n",
    "    sv_matrix = []\n",
    "\n",
    "    for j in range(len(hyper_pars)):\n",
    "        svc = SVR(\n",
    "            C = hyper_pars[j][0],\n",
    "            epsilon = hyper_pars[j][1],\n",
    "\n",
    "            kernel='rbf',\n",
    "\n",
    "            gamma = hyper_pars[j][2],\n",
    "\n",
    "        )\n",
    "        svc.fit(X_design, y_design)\n",
    "\n",
    "        sv_matrix.append(\n",
    "            np.array([hyper_pars[j][0], \n",
    "                      hyper_pars[j][1], \n",
    "                      hyper_pars[j][2],\n",
    "                      svc.n_support_.sum()/N_design\n",
    "                     ])\n",
    "        )\n",
    "\n",
    "        model_list.append(svc)\n",
    "\n",
    "    sv_matrix = pd.DataFrame(np.array(sv_matrix))\n",
    "    #sv_matrix = sv_matrix.rename(mapper={0:'param_C', 1:'param_epsilon', 2:'param_gamma', 3:'fsv'}, axis=1)\n",
    "    sv_matrix = sv_matrix.rename(mapper={0:'param_C', 1:'param_epsilon', 2:'param_gamma', 3:'fsv'}, axis=1)\n",
    "    return sv_matrix, model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6327b5d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# number of support vector for each model included in the grid search fixed a hyp. **by heatmap**\n",
    "\n",
    "sv_a, sv_b = sv_analysis_rbf(a_rbf_1, y_1_design)[0], sv_analysis_rbf(b_rbf_1, y_1_design)[0]\n",
    "\n",
    "score_var='fsv'\n",
    "\n",
    "fix_1 = 'param_epsilon'\n",
    "\n",
    "var_1= 'param_C'\n",
    "var_2= 'param_gamma'\n",
    "\n",
    "heatmap_3(sv_a, sv_a, fix_1, var_1, var_2, score_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  print the performance of the best model \n",
    "\n",
    "N_design = X_design.shape[0] \n",
    "\n",
    "rbf_final_1 = grid_rbf_1.best_estimator_\n",
    "\n",
    "print('best model choosen:\\n{}'.format(rbf_final_1))\n",
    "\n",
    "#print('number of support vectors:\\n{}'.format(rbf_final_1.n_support_.sum()))\n",
    "print('fraction of support vectors:\\n{}'.format(round_it(rbf_final_1.n_support_.sum()/N_design,2)))\n",
    "\n",
    "print('validation MAE:\\n{}'.format(-round_it(b_rbf_1.iloc[np.argmin(sv_b['fsv'])]['mean_test_score'], 3)) )\n",
    "\n",
    "y_pred_1 = rbf_final_1.predict(X_test)\n",
    "print('test MAE:\\n{}'.format(round_it(mean_absolute_error(y_1_test, y_pred_1), 4)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5333ec",
   "metadata": {},
   "source": [
    "### Sigmoidal kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28317e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) choice of hyperpar.'s ranges to explore\n",
    "\n",
    "C_interval_sigmoid = np.logspace(-3, 3, 7)\n",
    "gamma_interval_sigmoid = np.logspace(-3, 3, 7)\n",
    "coef0_interval_sigmoid = np.logspace(-4, -2, 3)\n",
    "eps_interval = np.logspace(-1, 0, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e8994",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 2) grid search in practice: FIRST RUN THE PREVIOUS CODE!\n",
    "\n",
    "param_grid_sigmoid_1= {\n",
    "    \n",
    "    'C': C_interval_sigmoid,  \n",
    "    'epsilon': eps_interval,\n",
    "    \n",
    "    'kernel': ['sigmoid'],  \n",
    "    \n",
    "    'gamma': gamma_interval_sigmoid, \n",
    "    'coef0': coef0_interval_sigmoid, \n",
    "    \n",
    "}\n",
    "\n",
    "grid_sigmoid_1 = my_grid_search(param_grid_sigmoid_1, y_1_design, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4030ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of useful dataframe\n",
    "\n",
    "#a_sigmoid_1 = pd.DataFrame(grid_sigmoid_1.cv_results_)\n",
    "a_sigmoid_1 = pd.read_csv('cup/a_sigmoid_1_first.csv')\n",
    "\n",
    "b_sigmoid_1 = a_sigmoid_1[a_sigmoid_1['rank_test_score'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f26e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_4(a, b, fix_1, fix_2, var_1, var_2, score_var):\n",
    "\n",
    "\n",
    "\n",
    "    X = np.unique(b[[fix_1, fix_2]].values.astype(None), axis=0)\n",
    "\n",
    "    for j in range(len(X)):\n",
    "        plt.figure(j)\n",
    "\n",
    "        matrix = a[(a[fix_1] == X[j][0]) & (a[fix_2] == X[j][1])]\n",
    "        matrix = matrix[[var_1, var_2, score_var]]\n",
    "        \n",
    "        glue = matrix.pivot(var_1, var_2, score_var)\n",
    "        sns.heatmap(glue, cmap=\"crest\", linewidth=.5)\n",
    "        plt.title('{}={}, {}={}'.format(fix_1, X[j][0], fix_2, X[j][1]))\n",
    "\n",
    "    plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0911f386",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "heatmap_4(a_sigmoid_1, a_sigmoid_1 ,'param_coef0', 'param_epsilon', 'param_C', 'param_gamma', 'mean_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9478556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sv_analysis_sigmoid(df, y):\n",
    "    \n",
    "    hyper_pars = df[['param_C', 'param_epsilon', 'param_gamma', 'param_coef0']].values\n",
    "    model_list = []\n",
    "    sv_matrix = []\n",
    "\n",
    "    for j in range(len(hyper_pars)):\n",
    "        svr = SVR(\n",
    "            C = hyper_pars[j][0],\n",
    "            epsilon = hyper_pars[j][1],\n",
    "\n",
    "            kernel='sigmoid',\n",
    "\n",
    "            gamma = hyper_pars[j][2],\n",
    "            coef0 = hyper_pars[j][3],\n",
    "\n",
    "        )\n",
    "        svr.fit(X, y)\n",
    "\n",
    "        sv_matrix.append(\n",
    "            np.array([hyper_pars[j][0], \n",
    "                      hyper_pars[j][1], \n",
    "                      hyper_pars[j][2],\n",
    "                      hyper_pars[j][3],\n",
    "                      round(svr.n_support_.sum()/N_design, 2)\n",
    "                     ])\n",
    "        )\n",
    "\n",
    "        model_list.append(svr)\n",
    "\n",
    "    sv_matrix = pd.DataFrame(np.array(sv_matrix))\n",
    "    sv_matrix = sv_matrix.rename(mapper={\n",
    "        0:'param_C', 1:'param_epsilon', 2:'param_gamma', 3:'param_coef0', 4:'fsv'}, axis=1)\n",
    "    return sv_matrix, model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2998ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.a) number of support vector for each model included in the grid search **by heatmap**\n",
    "\n",
    "sv_a = sv_analysis_sigmoid(a_sigmoid_1, X_design, y_1_design)[0]\n",
    "sv_b = sv_analysis_sigmoid(b_sigmoid_1, X_design, y_1_design)[0]\n",
    "\n",
    "score_var='fsv'\n",
    "\n",
    "fix_1 = 'param_epsilon'\n",
    "fix_2 = 'param_coef0'\n",
    "\n",
    "var_1= 'param_C'\n",
    "var_2= 'param_gamma'\n",
    "\n",
    "heatmap_4(sv_a, sv_a, fix_1, fix_2, var_1, var_2, score_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad235fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) choice of the best model \n",
    "\n",
    "N_design = X_design.shape[0] \n",
    "\n",
    "sv_b, model_list_b = sv_analysis_sigmoid(b_sigmoid_1, X_design, y_1_design)\n",
    "\n",
    "sigmoid_final = grid_sigmoid_1.best_estimator_\n",
    "\n",
    "print('best model choosen:\\n{}'.format(sigmoid_final))\n",
    "\n",
    "#print('number of support vectors:\\n{}'.format(sigmoid_final.n_support_.sum()))\n",
    "print('fraction of support vectors:\\n{}'.format(round_it(sigmoid_final.n_support_.sum()/N_design,2)))\n",
    "\n",
    "print('validation MAE:\\n{}'.format(-round_it(b_sigmoid_1.iloc[np.argmin(sv_b['fsv'])]['mean_test_score'], 3)) )\n",
    "\n",
    "y_pred_1 = sigmoid_final.predict(X_test)\n",
    "print('test MAE:\\n{}'.format(round_it(mean_absolute_error(y_1_test, y_pred_1), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211e0ee",
   "metadata": {},
   "source": [
    "## Insights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df68ba6",
   "metadata": {},
   "source": [
    "We want to show the relationship between the size of the training set and the fsv(fraction of support vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff904cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sv = train_test_split(\n",
    "    X_design, y_1_design, test_size=0.2, random_state=0, shuffle=True)[1]\n",
    "\n",
    "y_sv = train_test_split(\n",
    "    X_design, y_1_design, test_size=0.2, random_state=0, shuffle=True)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deef89ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sv_a, sv_b = sv_analysis_sigmoid(a_sigmoid_1, X_sv, y_sv)[0], sv_analysis_sigmoid(b_sigmoid_1, X_sv, y_sv)[0]\n",
    "\n",
    "score_var='fsv'\n",
    "\n",
    "fix_1 = 'param_epsilon'\n",
    "fix_2 = 'param_coef0'\n",
    "\n",
    "var_1= 'param_C'\n",
    "var_2= 'param_gamma'\n",
    "\n",
    "heatmap_4(sv_a, sv_a, fix_1, fix_2, var_1, var_2, score_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182c5d66",
   "metadata": {},
   "source": [
    "Does the previous approach make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d443b47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fsv_train_sigmoid(X , y, C, eps, gamma, coef0):\n",
    "    \n",
    "    fsv_list=[]\n",
    "    axis_list=[]\n",
    "    \n",
    "    for n in range(1, 10):\n",
    "        \n",
    "        #creation of variable training set\n",
    "        x_sv = train_test_split(\n",
    "        X, y, test_size=n/10, random_state=0, shuffle=True)[1]\n",
    "\n",
    "        y_sv = train_test_split(\n",
    "        X, y, test_size=n/10, random_state=0, shuffle=True)[3]\n",
    "        \n",
    "        N_sv=x_sv.shape[0]\n",
    "        #set hyp.\n",
    "        svr = SVR(\n",
    "            C = C ,\n",
    "            epsilon = eps,\n",
    "\n",
    "            kernel= 'sigmoid',\n",
    "\n",
    "            gamma = gamma,\n",
    "            coef0 = coef0,\n",
    "\n",
    "        )\n",
    "        #fit the model with variable set\n",
    "        svr.fit(x_sv, y_sv)\n",
    "        \n",
    "        axis_list.append(n/10)\n",
    "        fsv_list.append(svr.n_support_.sum()/N_sv)\n",
    "        \n",
    "        \n",
    "    fsv_list=np.array(fsv_list)\n",
    "    plt.plot(axis_list, fsv_list)\n",
    "    \n",
    "    m=fsv_list.mean()\n",
    "    sigma=fsv_list.std()\n",
    "    \n",
    "    plt.plot([k/10 for k in range(1,10)], np.ones(len(fsv_list))*m, color='r', \n",
    "             linestyle='--', label='fsv = {}+-{}'.format(round_it(m,2), round_it(sigma,1)))\n",
    "\n",
    "#     plt.plot([k/10 for k in range(1,10)], np.ones(len(fsv_list))*(m+sigma), color='r', linestyle='--')\n",
    "#     plt.plot([k/10 for k in range(1,10)], np.ones(len(fsv_list))*(m-sigma), color='r', linestyle='--')\n",
    "    \n",
    "    plt.ylabel('fsv')\n",
    "    plt.xlabel('fraction of the entire design set')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    print('fsv = {}+-{}'.format(round_it(m,2), round_it(sigma,1)))\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "C=1000\n",
    "eps=1\n",
    "gamma=3e-6\n",
    "coef0=0.2\n",
    "\n",
    "fsv_train_sigmoid(X_design , y_1_design, C, eps, gamma, coef0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7114538f",
   "metadata": {},
   "source": [
    "We want to provide a final model trained on the entire X_design. However, can we check the sv for each model of the GS on a fraction of X_design? \n",
    "\n",
    "Let us consider the previous. For those input values we obtain interesting observation: starting  from (0.1xlen(X_design), **fsv=0.9** ) to \n",
    "(0.9xlen(X_design), **fsv=0.5**). So to have a complete view of support vectors for each model(cell of GridSearch) is more reliable train the models on the entire design test. Or anyway train the final model on the same fraction of X_design used for the check phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1405807f",
   "metadata": {},
   "source": [
    "## Target 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a55a94",
   "metadata": {},
   "source": [
    "### RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b802715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) choice of hyperpar.'s ranges to explore\n",
    "\n",
    "C_interval_rbf = np.logspace(-2, 4, 7)\n",
    "gamma_interval_rbf = np.logspace(-4, 2, 7) \n",
    "epsilon_interval = np.logspace(-2, 0, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab2630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 2) grid search in practice: FIRST RUN THE PREVIOUS CODE!\n",
    "param_grid_rbf_2 = {\n",
    "    'C': C_interval_rbf, #must be strictly positive  \n",
    "    'epsilon': eps_interval,\n",
    "    \n",
    "    'kernel': ['rbf'],\n",
    "    \n",
    "    'gamma': gamma_interval_rbf #gamma must be greater than 0      \n",
    "    \n",
    "}\n",
    "\n",
    "grid_rbf_2 = my_grid_search(param_grid_rbf_2, y_2_design, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa77400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of useful dataframe\n",
    "\n",
    "a_rbf_2 = pd.DataFrame(grid_rbf_2.cv_results_)\n",
    "\n",
    "b_rbf_2 = a_rbf_2[a_rbf_2['rank_test_score'] == 1]  #cv_results_ restricted to model with best MAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c36ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap to visualize graphically the grid search fixing a hyp.\n",
    "\n",
    "heatmap_3(a_rbf_2, a_rbf_2, 'param_epsilon', 'param_C', 'param_gamma', 'mean_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa031e",
   "metadata": {},
   "source": [
    "- SVR for target 2 works worse than target 1 with the same coarse GridSearch\n",
    "\n",
    "- same reasoning done for target 1: pretty similiar GrisSearch for different values of eps, maybe for eps=1 is a bit worse. BUT taking into account the nsv it's more reasonable in terms of efficiency focus our attention on eps=1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dd4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "print('r = {}'.format(spearmanr(a_rbf_1[a_rbf_1['mean_test_score'] >= -0.9][['param_C', 'param_gamma']].values)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e084e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) (plot) one hyp. vs validatio_accuracy fixing the others hyp. (at values that maximize the validation_accuracy)\n",
    "\n",
    "score_var='mean_test_score'\n",
    "\n",
    "fix_1= 'param_epsilon'\n",
    "fix_2= 'param_gamma'\n",
    "\n",
    "var_1= 'param_C'\n",
    "\n",
    "plot_3(a_rbf_1[a_rbf_1['param_epsilon'] == 1.0], fix_1, fix_2, var_1, score_var, 'log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3950cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 7.a) number of support vector for each model included in the grid search **by heatmap**\n",
    "\n",
    "sv_a, sv_b = sv_analysis_rbf(a_rbf_2, y_2_design)[0], sv_analysis_rbf(b_rbf_2, y_2_design)[0]\n",
    "\n",
    "score_var='n_support_vectors'\n",
    "\n",
    "fix_1 = 'param_epsilon'\n",
    "\n",
    "var_1= 'param_C'\n",
    "var_2= 'param_gamma'\n",
    "\n",
    "heatmap_3(sv_a, sv_a, fix_1, var_1, var_2, score_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d9db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) choice of the model with lowest number of support vector\n",
    "\n",
    "N_design = X_design.shape[0] \n",
    "\n",
    "sv_b, model_list_b = sv_analysis_rbf(b_rbf_2, y_2_design)\n",
    "\n",
    "rbf_final_2 = grid_rbf_2.best_estimator_\n",
    "\n",
    "print('best model choosen:\\n{}'.format(rbf_final_2))\n",
    "print('number of support vectors:\\n{}'.format(rbf_final_2.n_support_.sum()))\n",
    "print('fraction of support vectors:\\n{}'.format(round_it(rbf_final_2.n_support_.sum()/N_design,2)))\n",
    "\n",
    "print('validation MAE:\\n{}'.format(-round_it(b_rbf_2.iloc[np.argmin(sv_b['fsv'])]['mean_test_score'], 4)) )\n",
    "\n",
    "y_pred_2 = rbf_final_2.predict(X_test)\n",
    "print('test MAE:\\n{}'.format(round_it(mean_absolute_error(y_2_test, y_pred_2), 4)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de180f",
   "metadata": {},
   "source": [
    "### Sigmoid kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfe3e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) choice of hyperpar.'s ranges to explore\n",
    "\n",
    "C_interval_sigmoid = np.logspace(3, 4, 7)\n",
    "gamma_interval_sigmoid = np.logspace(-4, -3, 7)\n",
    "coef0_interval_sigmoid = np.logspace(-3, -1, 3)\n",
    "eps_interval = [1.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4a4bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 2)\n",
    "\n",
    "param_grid_sigmoid_2={\n",
    "    \n",
    "    'C': C_interval_sigmoid,  \n",
    "    'epsilon': eps_interval,\n",
    "    \n",
    "    'kernel': ['sigmoid'],  \n",
    "    \n",
    "    'gamma': gamma_interval_sigmoid, \n",
    "    'coef0': coef0_interval_sigmoid,  \n",
    "}\n",
    "\n",
    "grid_sigmoid_2 = my_grid_search(param_grid_sigmoid_2, y_2_design, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91650e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 2)\n",
    "\n",
    "param_grid_sigmoid_2={\n",
    "    \n",
    "    'C': [1e3],  \n",
    "    'epsilon': [1],\n",
    "    \n",
    "    'kernel': ['sigmoid'],  \n",
    "    \n",
    "    'gamma': [1e-4], \n",
    "    'coef0': [1e-3],  \n",
    "}\n",
    "\n",
    "grid_sigmoid_2 = my_grid_search(param_grid_sigmoid_2, y_2_design, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624b1094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of useful dataframe\n",
    "\n",
    "a_sigmoid_2 = pd.DataFrame(grid_sigmoid_2.cv_results_)\n",
    "#a_sigmoid_2 = pd.read_csv('cup/a_sigmoid_2_first.csv')\n",
    "\n",
    "b_sigmoid_2 = a_sigmoid_2[a_sigmoid_2['rank_test_score'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b02f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_4(\n",
    "    a_sigmoid_2, \n",
    "    a_sigmoid_2 ,\n",
    "    'param_coef0', \n",
    "    'param_epsilon', \n",
    "    'param_C', \n",
    "    'param_gamma', \n",
    "    'mean_test_score'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857ca690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.a) number of support vector for each model included in the grid search **by heatmap**\n",
    "\n",
    "sv_a = sv_analysis_sigmoid(a_sigmoid_2, X_design, y_2_design)[0]\n",
    "sv_b = sv_analysis_sigmoid(b_sigmoid_2, X_design, y_2_design)[0]\n",
    "\n",
    "score_var='fsv'\n",
    "\n",
    "fix_1 = 'param_epsilon'\n",
    "fix_2 = 'param_coef0'\n",
    "\n",
    "var_1= 'param_C'\n",
    "var_2= 'param_gamma'\n",
    "\n",
    "heatmap_4(sv_a, sv_a, fix_1, fix_2, var_1, var_2, score_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbdd2da",
   "metadata": {},
   "source": [
    "for the last GS we notice very well the relationship between areas with higher validation score and lower nsv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e93e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) choice of the best model \n",
    "\n",
    "N_design = X_design.shape[0] \n",
    "\n",
    "sv_b, model_list_b = sv_analysis_sigmoid(b_sigmoid_2, X_design, y_2_design)\n",
    "\n",
    "sigmoid_final = grid_sigmoid_2.best_estimator_\n",
    "\n",
    "print('best model choosen:\\n{}'.format(sigmoid_final))\n",
    "\n",
    "print('number of support vectors:\\n{}'.format(sigmoid_final.n_support_.sum()))\n",
    "print('fraction of support vectors:\\n{}'.format(round_it(sigmoid_final.n_support_.sum()/N_design, 2)))\n",
    "\n",
    "print('validation MAE:\\n{}'.format(-round_it(b_sigmoid_2.iloc[np.argmin(sv_b['fsv'])]['mean_test_score'], 4)) )\n",
    "\n",
    "y_pred = sigmoid_final.predict(X_test)\n",
    "print('test MAE:\\n{}'.format(round_it(mean_absolute_error(y_2_test, y_pred), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fcf652",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9af3a4",
   "metadata": {},
   "source": [
    "Clearly from the previous output we observe that the best results come out from RBF kernel. Taking into account both the target variable let's compute the final MEE for the SVR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1209088",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_1=np.square(y_1_test - rbf_final_1.predict(X_test))\n",
    "e_2=np.square(y_2_test - rbf_final_2.predict(X_test))\n",
    "              \n",
    "MEE_final = (1/X_test.shape[0])*np.sqrt(e_1 + e_2).sum()\n",
    "print('MEE={}'.format(round(MEE_final, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
