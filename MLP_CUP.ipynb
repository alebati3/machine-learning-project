{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7713a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "RANDOM_STATE = 0\n",
    "MODEL = MLPRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec9d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pd.read_csv('ML-CUP22-TR.csv', skiprows=7, header=None)\n",
    "tr = tr.drop([0], axis=1).rename(columns={i:i-1 for i in tr.columns})\n",
    "blind_ts = pd.read_csv('ML-CUP22-TS.csv', skiprows=7, header=None)\n",
    "blind_ts = blind_ts.drop([0], axis=1).rename(columns={i:i-1 for i in blind_ts.columns})\n",
    "\n",
    "X_blind = blind_ts.values\n",
    "X = tr.iloc[:,:9].values\n",
    "Y = tr.iloc[:,9:].values\n",
    "# HOLD-OUT DESIGNER SET - TEST SET\n",
    "X_tr, X_tt, Y_tr, Y_tt = train_test_split(\n",
    "    X, Y, test_size=0.3, random_state=RANDOM_STATE, shuffle=True)\n",
    "# HOLD-OUT TRAINING - VALIDATION\n",
    "X_inner_tr, X_val, Y_inner_tr, Y_val = train_test_split(\n",
    "    X_tr, Y_tr, test_size=0.2, random_state=RANDOM_STATE, shuffle=True) \n",
    "# we choose a val size of 0.2*X_tr.shape[0], to save 80% of data for the actual training\n",
    "\n",
    "# DIVIDING THE 2 TARGETS Y\n",
    "y1_tr, y2_tr = Y_tr[:,0], Y_tr[:,1]\n",
    "y1_inner_tr, y2_inner_tr = Y_inner_tr[:,0], Y_inner_tr[:,1]\n",
    "y1_val, y2_val = Y_val[:,0], Y_val[:,1]\n",
    "y1_tt, y2_tt = Y_tt[:,0], Y_tt[:,1]\n",
    "\n",
    "# RESCALING OF THE DATA (MEAN=0, SIGMA=1)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_tt = scaler.transform(X_tt)\n",
    "X_blind = scaler.transform(X_blind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79e3f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_function(X_tr, y_tr, model, type_of_search, n_iter):\n",
    "    '''\n",
    "    Function useful to avoid the repetition of the grid/random search in each cell\n",
    "    '''\n",
    "    if (type_of_search=='rand'):\n",
    "        grid = RandomizedSearchCV(\n",
    "            model,\n",
    "            param_distributions=param_grid,\n",
    "            cv=KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE), # not a repeatedKfold, would have been too time consuming\n",
    "            n_jobs=-1,\n",
    "            n_iter=n_iter,\n",
    "            refit='neg_mean_absolute_error',\n",
    "            scoring='neg_mean_absolute_error',\n",
    "            random_state=RANDOM_STATE,\n",
    "        )\n",
    "    if type_of_search=='grid':\n",
    "        grid = GridSearchCV(\n",
    "            model,\n",
    "            param_grid=param_grid,\n",
    "            scoring='neg_mean_absolute_error',\n",
    "            cv=KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE), # not a repeatedKfold, would have been too time consuming\n",
    "            n_jobs=-1,\n",
    "            refit='neg_mean_absolute_error',\n",
    "        )\n",
    "    grid.fit(X_tr, y_tr)\n",
    "    return grid, pd.DataFrame(grid.cv_results_).sort_values(by='rank_test_score',axis=0)\n",
    "\n",
    "def MSE_vs_Epochs(model, X_tr, X_val, y_tr, y_val, epochs, plotting):\n",
    "    '''\n",
    "    Function that returns training and validation errors for each epoch. \n",
    "    If plotting==True, it also plots the two curves against the number of epochs.\n",
    "    In case we select 0 epochs, it will automatically select the best number of epochs,\n",
    "    depending on the stopping point of the model over the training set.\n",
    "\n",
    "    '''\n",
    "    if epochs==0: \n",
    "        model.fit(X_tr, y_tr)\n",
    "        epochs = model.n_iter_\n",
    "    model_ = clone(model)\n",
    "    model_.warm_start = True\n",
    "    tr_err_curve, val_err_curve = [], []\n",
    "    for i in range(epochs):\n",
    "        model_.partial_fit(X_tr,y_tr)\n",
    "        tr_err = mean_squared_error(y_tr, model_.predict(X_tr))\n",
    "        tr_err_curve.append(tr_err)\n",
    "        val_err = mean_squared_error(y_val, model_.predict(X_val))\n",
    "        val_err_curve.append(val_err)\n",
    "    if plotting==True:\n",
    "        fig_learn_curve = plt.figure()\n",
    "        plt.plot(tr_err_curve, linewidth=3, label='MSE vs #epochs training')\n",
    "        plt.plot(val_err_curve, linewidth=3, linestyle='--', label='MSE vs #epochs validation')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title('MSE vs Epochs', fontsize=20)\n",
    "        plt.xlabel('Epoch', fontsize=15)\n",
    "        plt.ylabel('MSE', fontsize=15)\n",
    "        plt.xticks(fontsize=15)\n",
    "        plt.yticks(fontsize=15)\n",
    "        fig_loss = plt.figure()\n",
    "        plt.grid()\n",
    "        plt.title('Loss curve', fontsize=20)\n",
    "        plt.plot(model_.loss_curve_, linewidth=3)\n",
    "        plt.xlabel('Epoch', fontsize=15)\n",
    "        plt.ylabel('Loss', fontsize=15)\n",
    "        plt.xticks(fontsize=15)\n",
    "        plt.yticks(fontsize=15)\n",
    "        return tr_err_curve, val_err_curve, fig_learn_curve, fig_loss\n",
    "    return tr_err_curve, val_err_curve\n",
    "\n",
    "def mean_learning_curve(repetitions, model, X_tr, X_val, y_tr, y_val, epochs):\n",
    "    '''\n",
    "    A function that repeate the evaluation of the model for 'repetitions' times\n",
    "    and give in output the mean and the std dev for mse over training and validation sets.\n",
    "    It also plots the curve obtained, assigning to each point also the std dev found.\n",
    "    '''\n",
    "    tr_err_curves = []\n",
    "    val_err_curves = []\n",
    "    model = clone(model)\n",
    "    model.random_state = None\n",
    "    for i in range(repetitions):\n",
    "        tr_err_curve, val_err_curve = MSE_vs_Epochs(model, X_tr, X_val, y_tr, y_val, epochs, False)\n",
    "        tr_err_curves.append(tr_err_curve)\n",
    "        val_err_curves.append(val_err_curve)\n",
    "    tr_err_curves = pd.DataFrame(tr_err_curves)\n",
    "    val_err_curves = pd.DataFrame(val_err_curves)\n",
    "    epoch_v = np.arange(1,tr_err_curves.shape[1]+1,step=1)\n",
    "    mean_err_tr_per_epoch = np.array([np.mean(tr_err_curves.iloc[:,i]) for i in range(tr_err_curves.shape[1])])\n",
    "    mean_err_val_per_epoch = np.array([np.mean(val_err_curves.iloc[:,i]) for i in range(val_err_curves.shape[1])])\n",
    "    std_err_tr_per_epoch = np.array([np.std(tr_err_curves.iloc[:,i]) for i in range(tr_err_curves.shape[1])])\n",
    "    std_err_val_per_epoch = np.array([np.std(val_err_curves.iloc[:,i]) for i in range(val_err_curves.shape[1])])\n",
    "    fig = plt.figure()\n",
    "    plt.plot(epoch_v, mean_err_val_per_epoch, c='r', linestyle='--', label='MSE vs #epochs validation')\n",
    "    plt.plot(epoch_v, mean_err_tr_per_epoch, c='b', label='MSE vs #epochs training')\n",
    "    plt.fill_between(epoch_v, mean_err_tr_per_epoch-std_err_tr_per_epoch, mean_err_tr_per_epoch+std_err_tr_per_epoch, color='b', alpha=.1)\n",
    "    plt.fill_between(epoch_v, mean_err_val_per_epoch-std_err_val_per_epoch, mean_err_val_per_epoch+std_err_val_per_epoch, color='r', alpha=.1)\n",
    "    epoch_mean_err_val = epoch_v[np.argmin(mean_err_val_per_epoch)]\n",
    "    #plt.axvline(epoch_mean_err_val, color=\"grey\")\n",
    "    str_min_mean_err_val = 'epoch of the minimum for val. :'+str(epoch_mean_err_val)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.title('Learning curves', fontsize=20)\n",
    "    plt.xlabel('Epochs', fontsize=15)\n",
    "    plt.ylabel('MSE', fontsize=15)\n",
    "    model_to_return = clone(model)\n",
    "    model_to_return.random_state = model.random_state\n",
    "    for epoch in range(epoch_mean_err_val):\n",
    "        model_to_return.partial_fit(X_tr, y_tr) # here we fit the model until epoch=epoch_mean_err_val\n",
    "    return fig, mean_err_tr_per_epoch, mean_err_val_per_epoch, std_err_tr_per_epoch, std_err_val_per_epoch, model_to_return\n",
    "    \n",
    "    \n",
    "def mee(X_tt, Y_true, Y_pred):\n",
    "    '''\n",
    "    Function to compute Mean Euclidean Error for a 2-outputs Y\n",
    "    '''\n",
    "    return ((1/X_tt.shape[0])*np.sqrt(np.square(Y_true[:,0] - Y_pred[:,0]) + np.square(Y_true[:,1] - Y_pred[:,1]))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8db2a3",
   "metadata": {},
   "source": [
    "# Using invscaling learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77116bef",
   "metadata": {},
   "source": [
    "## 1 MLP network:\n",
    "a single model, with two outputs, to solve the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6239a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'activation': ['tanh', 'logistic'],\n",
    "    'alpha': [0, 0.01, 0.1],\n",
    "    'batch_size': [100], # mini batch\n",
    "    'early_stopping': [False], \n",
    "    'hidden_layer_sizes': [10, 100, (10,10), (10,10,10)],\n",
    "    'learning_rate': ['invscaling'],\n",
    "    'learning_rate_init': [0.1, 0.01, 0.001], # higher values because we decided to work with invscaling\n",
    "    'max_iter': [5000],\n",
    "    'momentum': [0], # we choose to avoid momentum, it can be noisy for mini batch/online\n",
    "    'n_iter_no_change': [50],\n",
    "    'nesterovs_momentum': [False], # we set it to false because we are not using full batch\n",
    "    'power_t': [0.3, 0.4, 0.5, 0.6], # the power we want to explore for the invscaling\n",
    "    'solver': ['sgd'],\n",
    "    'tol': [1e-3],\n",
    "    'random_state': [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "grid_all, df_sorted_all = search_function(X_tr, Y_tr, MODEL, 'grid', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d7a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_all.to_csv('MLP_CUP_grid_results/df_sorted_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7346eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_all.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a06fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df_sorted_all[:10]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf231d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model_all = clone(grid_all.best_estimator_)\n",
    "tr_err_curve, val_err_curve, fig1, fig2 = MSE_vs_Epochs(model_all, X_inner_tr, X_val, Y_inner_tr, Y_val, 0, True)\n",
    "fig1.savefig('images_MLP_CUP/model_Y/invscaling_model_Y_learn_curve.pdf')\n",
    "fig2.savefig('images_MLP_CUP/model_Y/invscaling_model_Y_loss.pdf')\n",
    "fig, mean_err_tr_per_epoch, mean_err_val_per_epoch, std_err_tr_per_epoch, std_err_val_per_epoch, final_model_all = mean_learning_curve(100, model_all, X_inner_tr, X_val, Y_inner_tr, Y_val, len(tr_err_curve))\n",
    "fig.savefig('images_MLP_CUP/model_Y/invscaling_model_Y_mean_learn_curve.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea3baba",
   "metadata": {},
   "source": [
    "### MEE obtained (assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e7ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_tt = final_model_all.predict(X_tt)\n",
    "Y_pred_inner_tr = final_model_all.predict(X_inner_tr)\n",
    "Y_pred_val = final_model_all.predict(X_val)\n",
    "print(f'MEE test = {mee(X_tt, Y_tt, Y_pred_tt)}')\n",
    "print(f'MEE inner training = {mee(X_inner_tr, Y_inner_tr, Y_pred_inner_tr)}')\n",
    "print(f'MEE validation = {mee(X_val, Y_val, Y_pred_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27daf7cd",
   "metadata": {},
   "source": [
    "## 2 MLP networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e303ea8e",
   "metadata": {},
   "source": [
    "### - y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c6677",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'activation': ['tanh', 'logistic'],\n",
    "    'alpha': [0.001, 0.01, 0.1],\n",
    "    'batch_size': [100],\n",
    "    'early_stopping': [False],\n",
    "    'hidden_layer_sizes': [10, 100, (10,10), (10,10,10)],\n",
    "    'learning_rate': ['invscaling'], \n",
    "    'learning_rate_init': [0.1, 0.01, 0.001],\n",
    "    'max_iter': [5000],\n",
    "    'momentum': [0], \n",
    "    'n_iter_no_change': [50],\n",
    "    'nesterovs_momentum': [False],\n",
    "    'power_t': [0.3, 0.4, 0.5, 0.6],\n",
    "    'solver': ['sgd'],\n",
    "    'tol': [1e-3],\n",
    "    'random_state': [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "grid1, df_sorted1 = search_function(X_tr, y1_tr, MODEL, 'grid', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a82fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted1.to_csv('MLP_CUP_grid_results/df_sorted1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d538ebe1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model1 = clone(grid1.best_estimator_)\n",
    "tr_err_curve, val_err_curve, fig1, fig2 = MSE_vs_Epochs(model1, X_inner_tr, X_val, y1_inner_tr, y1_val, 0, True)\n",
    "fig1.savefig('images_MLP_CUP/model_y1/invscaling_model_y1_learn_curve.pdf')\n",
    "fig2.savefig('images_MLP_CUP/model_y1/invscaling_model_y1_loss.pdf')\n",
    "fig, mean_err_tr_per_epoch, mean_err_val_per_epoch, std_err_tr_per_epoch, std_err_val_per_epoch, final_model1 = mean_learning_curve(10, model1, X_inner_tr, X_val, y1_inner_tr, y1_val, len(val_err_curve))\n",
    "fig.savefig('images_MLP_CUP/model_y1/invscaling_model_y1.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f33a392",
   "metadata": {},
   "source": [
    "### - y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78161d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'activation': ['tanh', 'logistic'],\n",
    "    'alpha': [0.001, 0.01, 0.1],\n",
    "    'batch_size': [100],\n",
    "    'early_stopping': [False],\n",
    "    'hidden_layer_sizes': [10, 100, (10,10), (10,10,10)],\n",
    "    'learning_rate': ['invscaling'], \n",
    "    'learning_rate_init': [0.1, 0.01, 0.001],\n",
    "    'max_iter': [5000],\n",
    "    'momentum': [0], \n",
    "    'n_iter_no_change': [50],\n",
    "    'nesterovs_momentum': [False],\n",
    "    'power_t': [0.3, 0.4, 0.5, 0.6],\n",
    "    'solver': ['sgd'],\n",
    "    'tol': [1e-3],\n",
    "    'random_state': [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "grid2, df_sorted2 = search_function(X_tr, y2_tr, MODEL, 'grid', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c3cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted2.to_csv('MLP_CUP_grid_results/df_sorted2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe5eb87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model2 = clone(grid2.best_estimator_)\n",
    "tr_err_curve, val_err_curve, fig1, fig2 = MSE_vs_Epochs(model2, X_inner_tr, X_val, y2_inner_tr, y2_val, 0, True)\n",
    "fig1.savefig('images_MLP_CUP/model_y2/invscaling_model_y2_learn_curve.pdf')\n",
    "fig2.savefig('images_MLP_CUP/model_y2/invscaling_model_y2_loss.pdf')\n",
    "fig, mean_err_tr_per_epoch, mean_err_val_per_epoch, std_err_tr_per_epoch, std_err_val_per_epoch, final_model2 = mean_learning_curve(10, model2, X_inner_tr, X_val, y2_inner_tr, y2_val, len(val_err_curve))\n",
    "plt.savefig('images_MLP_CUP/model_y2/invscaling_model_y2.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b4e02",
   "metadata": {},
   "source": [
    "### MEE obtained (assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_tt = np.column_stack([final_model1.predict(X_tt), final_model2.predict(X_tt)])\n",
    "Y_pred_inner_tr = np.column_stack([final_model1.predict(X_inner_tr), final_model2.predict(X_inner_tr)])\n",
    "Y_pred_val = np.column_stack([final_model1.predict(X_val), final_model2.predict(X_val)])\n",
    "\n",
    "print(f'MAE inner training y1 = {mean_absolute_error(y1_inner_tr, final_model1.predict(X_inner_tr))}')\n",
    "print(f'MAE inner training y2 = {mean_absolute_error(y2_inner_tr, final_model2.predict(X_inner_tr))}\\n')\n",
    "\n",
    "print(f'MAE validation y1 = {mean_absolute_error(y1_val, final_model1.predict(X_val))}')\n",
    "print(f'MAE validation y2 = {mean_absolute_error(y2_val, final_model2.predict(X_val))}\\n')\n",
    "\n",
    "print(f'MAE test y1 = {mean_absolute_error(y1_tt, final_model1.predict(X_tt))}')\n",
    "print(f'MAE test y2 = {mean_absolute_error(y2_tt, final_model2.predict(X_tt))}\\n')\n",
    "\n",
    "print(f'MEE test = {mee(X_tt, Y_tt, Y_pred_tt)}')\n",
    "print(f'MEE inner training = {mee(X_inner_tr, Y_inner_tr, Y_pred_inner_tr)}')\n",
    "print(f'MEE validation = {mee(X_val, Y_val, Y_pred_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf7bda6",
   "metadata": {},
   "source": [
    "# More investigations using other learning rate types (n_iter_no_change = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbbc8b",
   "metadata": {},
   "source": [
    "## y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa7fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes' : [1,10,100],\n",
    "    'activation' : ['relu', 'logistic', 'tanh'],\n",
    "    'solver' : ['sgd'],\n",
    "    'alpha' : [0, 1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    'batch_size' : [100],\n",
    "    'learning_rate' : ['constant', 'adaptive'],\n",
    "    'learning_rate_init' : [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    'max_iter' : [5000], \n",
    "    'tol' : [1e-4], \n",
    "    'momentum' : [0, 0.01, 0.1], \n",
    "    'nesterovs_momentum' : [False], # batch size è più vicina all'online che al totale del numero di punti\n",
    "    'early_stopping' : [False], # non serve, visto l'hold out iniziale\n",
    "    'n_iter_no_change' : [50],\n",
    "    'random_state' : [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "grid1_1, df_sorted1_1 = search_function(X_tr, y1_tr, MODEL, 'grid', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea069c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sorted1_1.to_csv('MLP_CUP_grid_results/df_sorted1_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476fcd22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model1_1 = clone(grid1_1.best_estimator_)\n",
    "tr_err_curve, val_err_curve, fig1, fig2 = MSE_vs_Epochs(model1_1, X_inner_tr, X_val, y1_inner_tr, y1_val, 1000, True)\n",
    "fig1.savefig('images_MLP_CUP/model_y1/other_lr_model_y1_learn_curve.pdf')\n",
    "fig2.savefig('images_MLP_CUP/model_y1/other_lr_model_y1_loss.pdf')\n",
    "fig, mean_err_tr_per_epoch, mean_err_val_per_epoch, std_err_tr_per_epoch, std_err_val_per_epoch, final_model1_1 = mean_learning_curve(10, model1_1, X_inner_tr, X_val, y1_inner_tr, y1_val, len(val_err_curve))\n",
    "plt.savefig('images_MLP_CUP/model_y1/other_lr_model1_1y1.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b7d0a1",
   "metadata": {},
   "source": [
    "## y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a6eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes' : [1,10,100],\n",
    "    'activation' : ['relu', 'logistic', 'tanh'],\n",
    "    'solver' : ['sgd'],\n",
    "    'alpha' : [0, 1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    'batch_size' : [100],\n",
    "    'learning_rate' : ['constant', 'adaptive'],\n",
    "    'learning_rate_init' : [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    'max_iter' : [5000], \n",
    "    'tol' : [1e-4], \n",
    "    'momentum' : [0, 0.01, 0.1], \n",
    "    'nesterovs_momentum' : [False], # batch size è più vicina all'online che al totale del numero di punti\n",
    "    'early_stopping' : [False], # non serve, visto l'hold out iniziale\n",
    "    'n_iter_no_change' : [50],\n",
    "    'random_state' : [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "grid2_1, df_sorted2_1 = search_function(X_tr, y2_tr, MODEL, 'grid', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2bf794",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted2_1.to_csv('MLP_CUP_grid_results/df_sorted2_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c17161",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model2_1 = clone(grid1.best_estimator_)\n",
    "tr_err_curve, val_err_curve, fig1, fig2 = MSE_vs_Epochs(model2_1, X_inner_tr, X_val, y2_inner_tr, y2_val, 0, True)\n",
    "fig1.savefig('images_MLP_CUP/model_y2/other_lr_model_y2_learn_curve.pdf')\n",
    "fig2.savefig('images_MLP_CUP/model_y2/other_lr_model_y2_loss.pdf')\n",
    "fig, mean_err_tr_per_epoch, mean_err_val_per_epoch, std_err_tr_per_epoch, std_err_val_per_epoch, final_model2_1 = mean_learning_curve(10, model2_1, X_inner_tr, X_val, y2_inner_tr, y2_val, len(val_err_curve))\n",
    "fig.savefig('images_MLP_CUP/model_y2/other_lr_model2_1y1.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f531c214",
   "metadata": {},
   "source": [
    "### MEE obtained (assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4043e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_tt = np.column_stack([final_model1_1.predict(X_tt), final_model2_1.predict(X_tt)])\n",
    "Y_pred_inner_tr = np.column_stack([final_model1_1.predict(X_inner_tr), final_model2_1.predict(X_inner_tr)])\n",
    "Y_pred_val = np.column_stack([final_model1_1.predict(X_val), final_model2_1.predict(X_val)])\n",
    "\n",
    "print(f'MAE inner training y1 = {mean_absolute_error(y1_inner_tr, final_model1_1.predict(X_inner_tr))}')\n",
    "print(f'MAE inner training y2 = {mean_absolute_error(y2_inner_tr, final_model2_1.predict(X_inner_tr))}\\n')\n",
    "\n",
    "print(f'MAE validation y1 = {mean_absolute_error(y1_val, final_model1_1.predict(X_val))}')\n",
    "print(f'MAE validation y2 = {mean_absolute_error(y2_val, final_model2_1.predict(X_val))}\\n')\n",
    "\n",
    "print(f'MAE test y1 = {mean_absolute_error(y1_tt, final_model1_1.predict(X_tt))}')\n",
    "print(f'MAE test y2 = {mean_absolute_error(y2_tt, final_model2_1.predict(X_tt))}\\n')\n",
    "\n",
    "print(f'MEE test = {mee(X_tt, Y_tt, Y_pred_tt)}')\n",
    "print(f'MEE inner training = {mee(X_inner_tr, Y_inner_tr, Y_pred_inner_tr)}')\n",
    "print(f'MEE validation = {mee(X_val, Y_val, Y_pred_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8713b5",
   "metadata": {},
   "source": [
    "## Single network MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dc2ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes' : [1,10,100],\n",
    "    'activation' : ['relu', 'logistic', 'tanh'],\n",
    "    'solver' : ['sgd'],\n",
    "    'alpha' : [0, 1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    'batch_size' : [100],\n",
    "    'learning_rate' : ['constant', 'adaptive'],\n",
    "    'learning_rate_init' : [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    'max_iter' : [5000], \n",
    "    'tol' : [1e-4], \n",
    "    'momentum' : [0, 0.01, 0.1], \n",
    "    'nesterovs_momentum' : [False], # batch size è più vicina all'online che al totale del numero di punti\n",
    "    'early_stopping' : [False], # non serve, visto l'hold out iniziale\n",
    "    'n_iter_no_change' : [50],\n",
    "    'random_state' : [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "grid_all_1, df_sorted_all_1 = search_function(X_tr, Y_tr, MODEL, 'grid', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab89b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_all_1[['params', 'mean_test_score', 'std_test_score']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe428775",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all_1 = clone(grid_all_1.best_estimator_)\n",
    "tr_err_curve, val_err_curve = MSE_vs_Epochs(model_all_1, X_inner_tr, X_val, Y_inner_tr, Y_val, 0, True)\n",
    "fig, mean_err_tr_per_epoch, mean_err_val_per_epoch, std_err_tr_per_epoch, std_err_val_per_epoch = mean_learning_curve(10, model_all_1, X_inner_tr, X_val, Y_inner_tr, Y_val, 0)\n",
    "plt.savefig('images/model_1Y.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8087385b",
   "metadata": {},
   "source": [
    "### MEE obtained (assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705eba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.column_stack([final_model1_1.predict(X_tt), final_model2_1.predict(X_tt)])\n",
    "mee(X_tt, Y_tt, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ff03f",
   "metadata": {},
   "source": [
    "# n_iter_no_change = 50 is to obtain convergence conditions (the runs took 4 hours... it means that, in a lot of cases, the MLP reaches 5000 iterations without obtaining the required n_iter_no_change). Let's low the n_iter_no_change to 10, tol to 1e-3 and max iter to 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b8cd07",
   "metadata": {},
   "source": [
    "## y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684a6e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes' : [10, 100, (10,10), (10,10,10)],\n",
    "    'activation' : ['relu', 'logistic', 'tanh'],\n",
    "    'solver' : ['sgd'],\n",
    "    'alpha' : [0, 1e-5, 1e-4, 1e-3],\n",
    "    'batch_size' : [100],\n",
    "    'learning_rate' : ['constant', 'adaptive'],\n",
    "    'learning_rate_init' : [1e-3, 1e-2, 1e-1],\n",
    "    'max_iter' : [2000], \n",
    "    'tol' : [1e-3], \n",
    "    'momentum' : [0, 0.01, 0.1], \n",
    "    'nesterovs_momentum' : [False], # batch size è più vicina all'online che al totale del numero di punti\n",
    "    'early_stopping' : [False], # non serve, visto l'hold out iniziale\n",
    "    'n_iter_no_change' : [10],\n",
    "    'random_state' : [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "grid1_2, df_sorted1_2 = search_function(X_tr, y1_tr, MODEL, 'grid', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b86b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sorted1_2.to_csv('MLP_CUP_grid_results/df_sorted1_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea42a9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model1_2 = clone(grid1_2.best_estimator_)\n",
    "tr_err_curve, val_err_curve, fig1, fig2 = MSE_vs_Epochs(model1_2, X_inner_tr, X_val, y1_inner_tr, y1_val, 0, True)\n",
    "fig1.savefig('images_MLP_CUP/model_y1/other_lr_lessruns_model_y1_learn_curve.pdf')\n",
    "fig2.savefig('images_MLP_CUP/model_y1/other_lr_lessruns_model_y1_loss.pdf')\n",
    "fig, mean_err_tr_per_epoch, mean_err_val_per_epoch, std_err_tr_per_epoch, std_err_val_per_epoch, final_model1_2 = mean_learning_curve(10, model1_2, X_inner_tr, X_val, y1_inner_tr, y1_val, len(val_err_curve))\n",
    "plt.savefig('images_MLP_CUP/model_y1/other_lr_lessruns_model1_2y1.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce67eaa",
   "metadata": {},
   "source": [
    "## y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66918775",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes' : [10, 100, (10,10), (10,10,10)],\n",
    "    'activation' : ['relu', 'logistic', 'tanh'],\n",
    "    'solver' : ['sgd'],\n",
    "    'alpha' : [0, 1e-5, 1e-4, 1e-3],\n",
    "    'batch_size' : [100],\n",
    "    'learning_rate' : ['constant', 'adaptive'],\n",
    "    'learning_rate_init' : [1e-3, 1e-2, 1e-1],\n",
    "    'max_iter' : [2000], \n",
    "    'tol' : [1e-3], \n",
    "    'momentum' : [0, 0.01, 0.1], \n",
    "    'nesterovs_momentum' : [False], # batch size è più vicina all'online che al totale del numero di punti\n",
    "    'early_stopping' : [False], # non serve, visto l'hold out iniziale\n",
    "    'n_iter_no_change' : [10],\n",
    "    'random_state' : [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "grid2_2, df_sorted2_2 = search_function(X_tr, y2_tr, MODEL, 'grid', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b77a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sorted2_2.to_csv('MLP_CUP_grid_results/df_sorted2_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d274bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2_2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87911ef5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model2_2 = clone(grid2_2.best_estimator_)\n",
    "tr_err_curve, val_err_curve, fig1, fig2 = MSE_vs_Epochs(model2_2, X_inner_tr, X_val, y2_inner_tr, y2_val, 0, True)\n",
    "fig1.savefig('images_MLP_CUP/model_y2/other_lr_lessruns_model_y2_learn_curve.pdf')\n",
    "fig2.savefig('images_MLP_CUP/model_y2/other_lr_lessruns_model_y2_loss.pdf')\n",
    "fig, mean_err_tr_per_epoch, mean_err_val_per_epoch, std_err_tr_per_epoch, std_err_val_per_epoch, final_model2_2 = mean_learning_curve(10, model2_2, X_inner_tr, X_val, y2_inner_tr, y2_val, len(val_err_curve))\n",
    "plt.savefig('images_MLP_CUP/model_y2/other_lr_lessruns_model2_2y2.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ac50d1",
   "metadata": {},
   "source": [
    "### MEE obtained (assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7c4749",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_tt = np.column_stack([final_model1_2.predict(X_tt), final_model2_2.predict(X_tt)])\n",
    "Y_pred_inner_tr = np.column_stack([final_model1_2.predict(X_inner_tr), final_model2_2.predict(X_inner_tr)])\n",
    "Y_pred_val = np.column_stack([final_model1_2.predict(X_val), final_model2_2.predict(X_val)])\n",
    "\n",
    "print(f'MAE inner training y1 = {mean_absolute_error(y1_inner_tr, final_model1_2.predict(X_inner_tr))}')\n",
    "print(f'MAE inner training y2 = {mean_absolute_error(y2_inner_tr, final_model2_2.predict(X_inner_tr))}\\n')\n",
    "\n",
    "print(f'MAE validation y1 = {mean_absolute_error(y1_val, final_model1_2.predict(X_val))}')\n",
    "print(f'MAE validation y2 = {mean_absolute_error(y2_val, final_model2_2.predict(X_val))}\\n')\n",
    "\n",
    "print(f'MAE test y1 = {mean_absolute_error(y1_tt, final_model1_2.predict(X_tt))}')\n",
    "print(f'MAE test y2 = {mean_absolute_error(y2_tt, final_model2_2.predict(X_tt))}\\n')\n",
    "\n",
    "print(f'MEE test = {mee(X_tt, Y_tt, Y_pred_tt)}')\n",
    "print(f'MEE inner training = {mee(X_inner_tr, Y_inner_tr, Y_pred_inner_tr)}')\n",
    "print(f'MEE validation = {mee(X_val, Y_val, Y_pred_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d62e69",
   "metadata": {},
   "source": [
    "## Single network MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c17d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes' : [10, 100, (10,10), (10,10,10)],\n",
    "    'activation' : ['relu', 'logistic', 'tanh'],\n",
    "    'solver' : ['sgd'],\n",
    "    'alpha' : [0, 1e-5, 1e-4, 1e-3],\n",
    "    'batch_size' : [100],\n",
    "    'learning_rate' : ['constant', 'adaptive'],\n",
    "    'learning_rate_init' : [1e-3, 1e-2, 1e-1],\n",
    "    'max_iter' : [2000], \n",
    "    'tol' : [1e-3], \n",
    "    'momentum' : [0, 0.01, 0.1], \n",
    "    'nesterovs_momentum' : [False], # batch size è più vicina all'online che al totale del numero di punti\n",
    "    'early_stopping' : [False], # non serve, visto l'hold out iniziale\n",
    "    'n_iter_no_change' : [10],\n",
    "    'random_state' : [RANDOM_STATE]\n",
    "}\n",
    "\n",
    "grid_all_2, df_sorted_all_2 = search_function(X_tr, Y_tr, MODEL, 'grid', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b24a18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sorted_all_2.to_csv('MLP_CUP_grid_results/df_sorted_all_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_all_2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117f9434",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_all_2 = clone(grid_all_2.best_estimator_)\n",
    "tr_err_curve, val_err_curve, fig1, fig2 = MSE_vs_Epochs(model_all_2, X_inner_tr, X_val, Y_inner_tr, Y_val, 0, True)\n",
    "fig1.savefig('images_MLP_CUP/model_Y/other_lr_lessruns_model_Y_learn_curve.pdf')\n",
    "fig2.savefig('images_MLP_CUP/model_Y/other_lr_lessruns_model_Y_loss.pdf')\n",
    "fig, mean_err_tr_per_epoch, mean_err_val_per_epoch, std_err_tr_per_epoch, std_err_val_per_epoch, final_model_all_2 = mean_learning_curve(10, model_all_2, X_inner_tr, X_val, Y_inner_tr, Y_val, len(val_err_curve))\n",
    "plt.savefig('images_MLP_CUP/model_Y/other_lr_lessruns_model_2Y.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32878faf",
   "metadata": {},
   "source": [
    "### MEE obtained (assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_tt = final_model_all_2.predict(X_tt)\n",
    "Y_pred_inner_tr = final_model_all_2.predict(X_inner_tr)\n",
    "Y_pred_val = final_model_all_2.predict(X_val)\n",
    "\n",
    "print(f'MEE test = {mee(X_tt, Y_tt, Y_pred_tt)}')\n",
    "print(f'MEE inner training = {mee(X_inner_tr, Y_inner_tr, Y_pred_inner_tr)}')\n",
    "print(f'MEE validation = {mee(X_val, Y_val, Y_pred_val)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
