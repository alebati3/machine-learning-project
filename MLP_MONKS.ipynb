{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32e8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_monks(path):\n",
    "    '''\n",
    "    Function to open monks datasets\n",
    "    Parameters    \n",
    "    '''\n",
    "    \n",
    "    file = open(path, 'r')\n",
    "    content = file.read().split('\\n') # split to separate different data\n",
    "    monks_df = pd.DataFrame([line.split(' ')[1:] for line in content][:-1]) # creation of the df using separation by ' '\n",
    "    \n",
    "    # The 3 lines below change names to the columns\n",
    "    dict_for_rename = {0:'target', monks_df.shape[1]-1:'id'}\n",
    "    dict_for_rename.update({i:i-1 for i in range(1,monks_df.shape[1]-1)})\n",
    "    monks_df = monks_df.rename(columns=dict_for_rename)\n",
    "    return monks_df\n",
    "\n",
    "def hot_encoding(df):\n",
    "    '''\n",
    "    Function useful for one hot encoding\n",
    "    '''\n",
    "    target_column = df.columns[0] # Columns referred to target \n",
    "    y = df[target_column] # selecting target value for each datapoint\n",
    "    y = y.values # from a pd. Dataframe to a np. array\n",
    "    y = np.array(y, dtype=int) # Convert target values from string to int\n",
    "    features_columns = df.columns[1:7] # Columns referred to cat. variables\n",
    "    X = df[features_columns] # selecting features columns for each datapoint   \n",
    "    columns = X.columns # Selecting the columns of X. These columns are just the categorical columns of df \n",
    "    X_hot = pd.get_dummies(X, columns=columns) # applying one-hot encoding to X features (from 6 dims to 17 dims)\n",
    "    X_hot = X_hot.values # from a pd. Dataframe to a np. array\n",
    "    return X_hot, y\n",
    "\n",
    "def model_results(X_train, y_train, X_val, y_val, clf, epochs):\n",
    "    '''\n",
    "    Fuction useful to plot learning curve until reached the selected number of epochs\n",
    "    and to give the scoring of the chosen model (from epochs number)\n",
    "    '''\n",
    "    clf_cloned = clone(clf)\n",
    "    clf_cloned.early_stopping = False\n",
    "    train_ACCs = []\n",
    "    val_ACCs = []\n",
    "    n_samples = X_train.shape[0]\n",
    "    classes = np.unique(y_train)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        clf_cloned.partial_fit(X_train, y_train, classes)\n",
    "        train_ACC = clf_cloned.score(X_train, y_train)\n",
    "        train_ACCs.append(train_ACC)\n",
    "        val_ACC = clf_cloned.score(X_val, y_val)\n",
    "        val_ACCs.append(val_ACC)\n",
    "\n",
    "    train_ACCs = np.array(train_ACCs)\n",
    "    val_ACCs = np.array(val_ACCs)\n",
    "    \n",
    "    fig1 = plt.figure()\n",
    "    plt.plot(train_ACCs, color='r')\n",
    "    plt.plot(val_ACCs, color='b', linestyle='--')\n",
    "    plt.legend(['Accuracy over TR', 'Accuracy over VAL'])\n",
    "    plt.title('Learning curves', fontsize=20)\n",
    "    plt.xlabel('#Epochs', fontsize=15)\n",
    "    plt.ylabel('Accuracy', fontsize=15)\n",
    "    plt.grid()\n",
    "    \n",
    "    fig2 = plt.figure()\n",
    "    plt.plot(clf_cloned.loss_curve_)\n",
    "    plt.grid()\n",
    "    plt.title('Loss vs #Epochs', fontsize=20)\n",
    "    plt.xlabel('#Epochs', fontsize=15)\n",
    "    plt.ylabel('Loss', fontsize=15)\n",
    "\n",
    "    print(f'inner train score = {clf_cloned.score(X_train, y_train)}')\n",
    "    print(f'validation score = {clf_cloned.score(X_val, y_val)}')\n",
    "    return train_ACCs, val_ACCs, fig1, fig2, clf_cloned\n",
    "\n",
    "monks1_train = open_monks('MONKS/monks-1.train')\n",
    "monks1_test = open_monks('MONKS/monks-1.test')\n",
    "\n",
    "monks2_train = open_monks('MONKS/monks-2.train')\n",
    "monks2_test = open_monks('MONKS/monks-2.test')\n",
    "\n",
    "monks3_train = open_monks('MONKS/monks-3.train')\n",
    "monks3_test = open_monks('MONKS/monks-3.test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d1b36d",
   "metadata": {},
   "source": [
    "# MONKS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826477a8",
   "metadata": {},
   "source": [
    "Below there are the grid searches for MONKS dataset. We decided, as suggested by the lectures on MONKS, to solve the problems in the easiest way possible:\n",
    "- few units\n",
    "- tanh as activation function\n",
    "- stochastic gradient descent method\n",
    "- alpha = 0, regularization shouldn't be necessary\n",
    "\n",
    "We choose to use:\n",
    "- learning rate 'invscaling' (which include also 'constant', thanks to power_t=0)\n",
    "- to explore only 2 learning rate starting values, higher than the standard proposal for the learning_rate_init (1e-3), given that in most of the explorations there will be an invscaling learning rate\n",
    "- an on-line type of descending (batch size = 1), which implies no nesterov momentum (on the lectures it's told that it improves performances only for the full batch mode)\n",
    "- 0 momentum, it shouldn't be necessary for the convergence (it's a small dataset)\n",
    "- standard tolerance, 1e-4 \n",
    "\n",
    "The first part of the code for each monk is the grid search as described above.\n",
    "\n",
    "In the second part of each section, after the hyperparameters selection, the training is divided in two sub-sets, 'inner training' and 'validation'. On the inner training set we retrain the model, using the evaluation set we choose at which epoch to stop the training. In this way we can show the learning curve and choose the right number of epochs for the assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e1bc4",
   "metadata": {},
   "source": [
    "# MONKS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98e7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_train, y_train = hot_encoding(monks1_train)\n",
    "X_test, y_test = hot_encoding(monks1_test)\n",
    "n_samples = monks1_train.shape[0]\n",
    "\n",
    "param_grid1 = {\n",
    "    'hidden_layer_sizes' : [3, 4, 5],\n",
    "    'activation' : ['tanh'],\n",
    "    'solver' : ['sgd'],\n",
    "    'alpha' : [0],\n",
    "    'batch_size' : [1],\n",
    "    'learning_rate' : ['invscaling'],\n",
    "    'learning_rate_init' : [1e-1, 1e-2],\n",
    "    'power_t' : [0, 0.1, 0.2, 0.3],\n",
    "    'max_iter' : [500], \n",
    "    'tol' : [1e-4], \n",
    "    'momentum' : [0], \n",
    "    'nesterovs_momentum' : [False],\n",
    "    'n_iter_no_change' : [10],\n",
    "}\n",
    "\n",
    "grid1 = GridSearchCV(\n",
    "    MLPClassifier(),\n",
    "    param_grid=param_grid1,\n",
    "    scoring='accuracy',\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True),\n",
    "    n_jobs=-1,\n",
    "    refit='accuracy',\n",
    ")\n",
    "\n",
    "grid1.fit(X_train, y_train)\n",
    "\n",
    "best_clf1 = grid1.best_estimator_\n",
    "plt.plot(best_clf1.loss_curve_)\n",
    "print(f'train score = {best_clf1.score(X_train, y_train)}')\n",
    "\n",
    "best_clf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6889ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid1.cv_results_).to_csv('MLP_MONKS_grid_results/MONKS1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e563d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(best_clf1.loss_curve_)\n",
    "plt.grid()\n",
    "plt.title('Loss vs #Epochs', fontsize=20)\n",
    "plt.xlabel('#Epochs', fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9526bb0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = hot_encoding(monks1_train)\n",
    "X_inner_train, X_val, y_inner_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=0, stratify=y_train, shuffle=True)\n",
    "X_test, y_test = hot_encoding(monks1_test)\n",
    "\n",
    "clf1 = clone(MLPClassifier(activation='tanh', alpha=0, batch_size=1, hidden_layer_sizes=4,\n",
    "              learning_rate='invscaling', learning_rate_init=0.1, max_iter=500,\n",
    "              momentum=0, nesterovs_momentum=False, power_t=0.2, solver='sgd', random_state=0))\n",
    "\n",
    "\n",
    "\n",
    "train_ACCs, val_ACCs, fig1, fig2, clf_cloned = model_results(X_inner_train, y_inner_train, X_val, y_val, clf1, 60)\n",
    "\n",
    "fig1.savefig('images_MLP_MONKS/learning_curve_MONKS1.pdf')\n",
    "fig2.savefig('images_MLP_MONKS/loss_curve_MONKS1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c65e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train score = {clf_cloned.score(X_inner_train, y_inner_train)}')\n",
    "print(f'val score = {clf_cloned.score(X_val, y_val)}')\n",
    "print(f'test score = {clf_cloned.score(X_test, y_test)}')\n",
    "print(f'train MSE = {mean_squared_error(y_inner_train, clf_cloned.predict(X_inner_train))}')\n",
    "print(f'val MSE = {mean_squared_error(y_val, clf_cloned.predict(X_val))}')\n",
    "print(f'test MSE = {mean_squared_error(y_test, clf_cloned.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e94092",
   "metadata": {},
   "source": [
    "# MONKS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8aa7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_train, y_train = hot_encoding(monks2_train)\n",
    "X_test, y_test = hot_encoding(monks2_test)\n",
    "n_samples = monks2_train.shape[0]\n",
    "\n",
    "param_grid2 = {\n",
    "    'hidden_layer_sizes' : [3, 4, 5],\n",
    "    'activation' : ['tanh'],\n",
    "    'solver' : ['sgd'],\n",
    "    'alpha' : [0],\n",
    "    'batch_size' : [1],\n",
    "    'learning_rate' : ['invscaling'],\n",
    "    'learning_rate_init' : [1e-1, 1e-2],\n",
    "    'power_t' : [0, 0.1, 0.2, 0.3],\n",
    "    'max_iter' : [500], \n",
    "    'tol' : [1e-4], \n",
    "    'momentum' : [0], \n",
    "    'nesterovs_momentum' : [False],\n",
    "    'n_iter_no_change' : [10],\n",
    "}\n",
    "\n",
    "grid2 = GridSearchCV(\n",
    "    MLPClassifier(),\n",
    "    param_grid=param_grid2,\n",
    "    scoring='accuracy',\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0),\n",
    "    n_jobs=-1,\n",
    "    refit='accuracy',\n",
    ")\n",
    "\n",
    "grid2.fit(X_train, y_train)\n",
    "\n",
    "best_clf2 = grid2.best_estimator_\n",
    "plt.plot(best_clf2.loss_curve_)\n",
    "print(f'test score = {best_clf2.score(X_test, y_test)}')\n",
    "print(f'train score = {best_clf2.score(X_train, y_train)}')\n",
    "\n",
    "best_clf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae87ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid2.cv_results_).to_csv('MLP_MONKS_grid_results/MONKS2_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd84032",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(best_clf2.loss_curve_)\n",
    "plt.grid()\n",
    "plt.title('Loss vs #Epochs', fontsize=20)\n",
    "plt.xlabel('#Epochs', fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5371e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = hot_encoding(monks2_train)\n",
    "X_inner_train, X_val, y_inner_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=0, stratify=y_train, shuffle=True)\n",
    "X_test, y_test = hot_encoding(monks2_test)\n",
    "\n",
    "clf2 = clone(MLPClassifier(activation='tanh', alpha=0, batch_size=1, hidden_layer_sizes=3,\n",
    "              learning_rate='invscaling', learning_rate_init=0.1, max_iter=500,\n",
    "              momentum=0, nesterovs_momentum=False, power_t=0.1, solver='sgd', random_state=0))\n",
    "\n",
    "train_ACCs_best2, test_ACCs_best2, fig1, fig2, clf_cloned = model_results(X_inner_train, y_inner_train,\n",
    "                                                                                         X_val, y_val,\n",
    "                                                                                         clf2, 100)\n",
    "fig1.savefig('images_MLP_MONKS/learning_curve_MONKS2.pdf')\n",
    "fig2.savefig('images_MLP_MONKS/loss_curve_MONKS2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee4aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train score = {clf_cloned.score(X_inner_train, y_inner_train)}')\n",
    "print(f'val score = {clf_cloned.score(X_val, y_val)}')\n",
    "print(f'test score = {clf_cloned.score(X_test, y_test)}')\n",
    "print(f'train MSE = {mean_squared_error(y_inner_train, clf_cloned.predict(X_inner_train))}')\n",
    "print(f'val MSE = {mean_squared_error(y_val, clf_cloned.predict(X_val))}')\n",
    "print(f'test MSE = {mean_squared_error(y_test, clf_cloned.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ab211e",
   "metadata": {},
   "source": [
    "# MONKS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0653a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_train, y_train = hot_encoding(monks3_train)\n",
    "X_test, y_test = hot_encoding(monks3_test)\n",
    "n_samples = monks3_train.shape[0]\n",
    "\n",
    "param_grid3 = {\n",
    "    'hidden_layer_sizes' : [3, 4, 5],\n",
    "    'activation' : ['tanh'],\n",
    "    'solver' : ['sgd'],\n",
    "    'alpha' : [0],\n",
    "    'batch_size' : [1],\n",
    "    'learning_rate' : ['invscaling'],\n",
    "    'learning_rate_init' : [1e-1, 1e-2],\n",
    "    'power_t' : [0, 0.1, 0.2, 0.3],\n",
    "    'max_iter' : [500], \n",
    "    'tol' : [1e-4], \n",
    "    'momentum' : [0], \n",
    "    'nesterovs_momentum' : [False],\n",
    "    'n_iter_no_change' : [10],\n",
    "}\n",
    "\n",
    "grid3 = GridSearchCV(\n",
    "    MLPClassifier(),\n",
    "    param_grid=param_grid3,\n",
    "    scoring='accuracy',\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0),\n",
    "    n_jobs=-1,\n",
    "    refit='accuracy',\n",
    ")\n",
    "\n",
    "grid3.fit(X_train, y_train)\n",
    "\n",
    "best_clf3 = grid3.best_estimator_\n",
    "plt.plot(best_clf3.loss_curve_)\n",
    "print(f'test score = {best_clf3.score(X_test, y_test)}')\n",
    "print(f'train score = {best_clf3.score(X_train, y_train)}')\n",
    "\n",
    "best_clf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310746d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid3.cv_results_).to_csv('MLP_MONKS_grid_results/MONKS3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4148d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(best_clf3.loss_curve_)\n",
    "plt.grid()\n",
    "plt.title('Loss vs #Epochs', fontsize=20)\n",
    "plt.xlabel('#Epochs', fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb365476",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = hot_encoding(monks3_train)\n",
    "X_inner_train, X_val, y_inner_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=0, stratify=y_train, shuffle=True)\n",
    "X_test, y_test = hot_encoding(monks3_test)\n",
    "\n",
    "clf3 = clone(MLPClassifier(activation='tanh', alpha=0, batch_size=1, hidden_layer_sizes=3,\n",
    "              learning_rate='invscaling', learning_rate_init=0.01, max_iter=500,\n",
    "              momentum=0, nesterovs_momentum=False, power_t=0.3, solver='sgd', random_state=0))\n",
    "\n",
    "train_ACCs_best3, test_ACCs_best3, fig1, fig2, clf_cloned = model_results(X_inner_train, y_inner_train,\n",
    "                                                                                         X_val, y_val,\n",
    "                                                                                         clf3, 200)\n",
    "\n",
    "fig1.savefig('images_MLP_MONKS/learning_curve_MONKS3.pdf')\n",
    "fig2.savefig('images_MLP_MONKS/loss_curve_MONKS3.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c8b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train score = {clf_cloned.score(X_inner_train, y_inner_train)}')\n",
    "print(f'val score = {clf_cloned.score(X_val, y_val)}')\n",
    "print(f'test score = {clf_cloned.score(X_test, y_test)}')\n",
    "print(f'train MSE = {mean_squared_error(y_inner_train, clf_cloned.predict(X_inner_train))}')\n",
    "print(f'val MSE = {mean_squared_error(y_val, clf_cloned.predict(X_val))}')\n",
    "print(f'test MSE = {mean_squared_error(y_test, clf_cloned.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ca4aa",
   "metadata": {},
   "source": [
    "# MONKS3 + REG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabef072",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = hot_encoding(monks3_train)\n",
    "X_inner_train, X_val, y_inner_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=0, stratify=y_train, shuffle=True)\n",
    "X_test, y_test = hot_encoding(monks3_test)\n",
    "\n",
    "clf3 = clone(MLPClassifier(activation='tanh', alpha=0, batch_size=1, hidden_layer_sizes=3,\n",
    "              learning_rate='constant', learning_rate_init=0.01, max_iter=500,\n",
    "              momentum=0, nesterovs_momentum=False, solver='sgd', random_state=0))\n",
    "clf3.alpha = 1e-1\n",
    "train_ACCs_best3, test_ACCs_best3, fig1, fig2, clf_cloned = model_results(X_inner_train, y_inner_train,\n",
    "                                                                                         X_val, y_val,\n",
    "                                                                                         clf3, 50)\n",
    "\n",
    "fig1.savefig('images_MLP_MONKS/learning_curve_MONKS3+reg.pdf')\n",
    "fig2.savefig('images_MLP_MONKS/loss_curve_MONKS3+reg.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7fa151",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train score = {clf_cloned.score(X_inner_train, y_inner_train)}')\n",
    "print(f'val score = {clf_cloned.score(X_val, y_val)}')\n",
    "print(f'test score = {clf_cloned.score(X_test, y_test)}')\n",
    "print(f'train MSE = {mean_squared_error(y_inner_train, clf_cloned.predict(X_inner_train))}')\n",
    "print(f'val MSE = {mean_squared_error(y_val, clf_cloned.predict(X_val))}')\n",
    "print(f'test MSE = {mean_squared_error(y_test, clf_cloned.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef105ffe",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
